{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6858c9d9-f151-4b6e-9b6a-cfc9642b4ae2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.tools import tool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "43243466-f3ca-444d-b2c3-50c0edf50944",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 109\u001b[0m\n\u001b[0;32m    107\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    108\u001b[0m     cfa \u001b[38;5;241m=\u001b[39m CognitiveFeedbackAgent()\n\u001b[1;32m--> 109\u001b[0m     \u001b[43mcfa\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[17], line 102\u001b[0m, in \u001b[0;36mCognitiveFeedbackAgent.run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    100\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    101\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 102\u001b[0m         input_text \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mUser: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m    103\u001b[0m         communication_type \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclassify_communication(input_text)\n\u001b[0;32m    104\u001b[0m         response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandle_communication(input_text, communication_type)\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\ipykernel\\kernelbase.py:1202\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[1;34m(self, prompt)\u001b[0m\n\u001b[0;32m   1200\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(msg)\n\u001b[1;32m-> 1202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1203\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1204\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1205\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   1206\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m   1207\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\ipykernel\\kernelbase.py:1245\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[1;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[0;32m   1242\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[0;32m   1243\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m   1244\u001b[0m     msg \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m-> 1245\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(msg) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1246\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1247\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from langchain import hub\n",
    "from langchain.agents import AgentExecutor\n",
    "from langchain.agents.output_parsers import ReActSingleInputOutputParser\n",
    "from langchain.agents.format_scratchpad import format_log_to_str\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.tools.render import render_text_description\n",
    "\n",
    "#for Bing\n",
    "import os\n",
    "from langchain.utilities import BingSearchAPIWrapper, SerpAPIWrapper\n",
    "\n",
    "# for Agent\n",
    "from langchain.agents import AgentExecutor, BaseSingleActionAgent, Tool, ZeroShotAgent\n",
    "from langchain.schema import AgentAction, AgentFinish\n",
    "\n",
    "# for LLM\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "\n",
    "# Maintenance\n",
    "from typing import Any, List, Tuple, Union\n",
    "\n",
    "# for Chain\n",
    "from langchain.chains import LLMChain\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class CognitiveFeedbackAgent:\n",
    "    def __init__(self):\n",
    "        # Initialize the LLM\n",
    "        self.llm = LlamaCpp(\n",
    "            model_path=\"llama-2-7b-chat.Q6_K.gguf\",\n",
    "            temperature=0.1,\n",
    "            max_tokens=500000,\n",
    "            top_p=0.9,\n",
    "            callback_manager=CallbackManager([StreamingStdOutCallbackHandler()]),\n",
    "            verbose=True,\n",
    "        )\n",
    "\n",
    "        # Set up the environment variables for Bing\n",
    "        os.environ[\"BING_SUBSCRIPTION_KEY\"] = \"02fa2d164e534dd69f2a586caba57cb6\"\n",
    "        os.environ[\"BING_SEARCH_URL\"] = \"https://api.bing.microsoft.com/v7.0/search\"\n",
    "\n",
    "        # Initialize Bing API and other components\n",
    "        bing_API_wrapper = BingSearchAPIWrapper()\n",
    "        bing_tool = Tool(\n",
    "            name=\"Bing\",\n",
    "            func=bing_API_wrapper.run,\n",
    "            description=\"useful for when you need descriptive answers to questions about current state of affairs\",\n",
    "            return_direct=False)\n",
    "\n",
    "        self.SERP_API_KEY = \"d38482db0efe9c48ec77ffdd165c3fb4d7144a6bf86b3604e4367b0a0fe17fdd\"\n",
    "        self.google_params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"gl\": \"uk\",\n",
    "            \"hl\": \"en\"}\n",
    "        self.google_API_wrapper = SerpAPIWrapper(serpapi_api_key=SERP_API_KEY, params=google_params)\n",
    "        self.google_tool =  Tool(\n",
    "            name=\"Internet\",\n",
    "            func=google_API_wrapper.run,\n",
    "            description=\"Useful for when you need short answers (e.g., a single number) to questions about current state of affairs\",\n",
    "            return_direct=True)\n",
    "        \n",
    "        self.tools = [self.google_tool]\n",
    "\n",
    "        # Define the prompt for the LLMChain\n",
    "        self.prompt = ZeroShotAgent.create_prompt(\n",
    "            self.tools,\n",
    "            prefix=\"Determine if the following question can be answered with your current knowledge. If not, you have access to following online search tools. You may try to break down the question to steps.\",\n",
    "            suffix=\"'Begin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}',\",\n",
    "            input_variables=[\"input\", \"agent_scratchpad\"]\n",
    "        )\n",
    "\n",
    "        # Create the LLMChain with OpenAI model\n",
    "        self.llm_chain = LLMChain(llm=self.llm, prompt=self.prompt)\n",
    "        \n",
    "        # Define the agent and agent executor\n",
    "        self.tool_names = [tool.name for tool in self.tools]\n",
    "        self.agent = ZeroShotAgent(llm_chain=self.llm_chain, allowed_tools=self.tool_names)\n",
    "        self.agent_executor = AgentExecutor.from_agent_and_tools(agent=self.agent, tools=self.tools, verbose=True)\n",
    "    \n",
    "    def classify_communication(self, input_text):\n",
    "        if \"?\" in input_text:\n",
    "            return 'factual question'\n",
    "        else:\n",
    "            return 'other'\n",
    "\n",
    "    def handle_communication(self, input_text, communication_type):\n",
    "        if communication_type == 'factual question':\n",
    "            response = self.agent_executor.invoke({\"input\": input_text})\n",
    "        else:\n",
    "            response = \"I'm not sure how to handle this type of communication.\"\n",
    "        return response\n",
    "\n",
    "    def run(self):\n",
    "        while True:\n",
    "            input_text = input(\"User: \")\n",
    "            communication_type = self.classify_communication(input_text)\n",
    "            response = self.handle_communication(input_text, communication_type)\n",
    "            print(f\"CFA: {response}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    cfa = CognitiveFeedbackAgent()\n",
    "    cfa.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1b6d3c15-55d1-4b40-9f9a-4490b14ee86b",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() missing 1 required positional argument: 'tool_input'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[15], line 18\u001b[0m\n\u001b[0;32m     10\u001b[0m     google_tool \u001b[38;5;241m=\u001b[39m  Tool(\n\u001b[0;32m     11\u001b[0m         name\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInternet\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     12\u001b[0m         func\u001b[38;5;241m=\u001b[39mgoogle_API_wrapper\u001b[38;5;241m.\u001b[39mrun,\n\u001b[0;32m     13\u001b[0m         description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUseful for when you need short answers (e.g., a single number) to questions about current state of affairs\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m     14\u001b[0m         return_direct\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m google_tool \n\u001b[1;32m---> 18\u001b[0m tools \u001b[38;5;241m=\u001b[39m [\u001b[43msearch_tool\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m]\n",
      "\u001b[1;31mTypeError\u001b[0m: __call__() missing 1 required positional argument: 'tool_input'"
     ]
    }
   ],
   "source": [
    "@tool\n",
    "def search_tool() -> str:\n",
    "    \"\"\" \"\"\"\n",
    "    SERP_API_KEY = \"d38482db0efe9c48ec77ffdd165c3fb4d7144a6bf86b3604e4367b0a0fe17fdd\"\n",
    "    google_params = {\n",
    "            \"engine\": \"google\",\n",
    "            \"gl\": \"uk\",\n",
    "            \"hl\": \"en\"}\n",
    "    google_API_wrapper = SerpAPIWrapper(serpapi_api_key=SERP_API_KEY, params=google_params)\n",
    "    google_tool =  Tool(\n",
    "        name=\"Internet\",\n",
    "        func=google_API_wrapper.run,\n",
    "        description=\"Useful for when you need short answers (e.g., a single number) to questions about current state of affairs\",\n",
    "        return_direct=True)\n",
    "\n",
    "    return google_tool \n",
    "            \n",
    "tools = [search_tool()]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "0eb3803e-fb4b-4f4b-bef5-d98110c4b589",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Joe Biden'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "google_API_wrapper.run(\"Current US president?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "cfeadb61-2778-417a-9615-720b4d411112",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Tool(name='Internet', description='Useful for when you need short answers (e.g., a single number) to questions about current state of affairs', return_direct=True, func=<bound method SerpAPIWrapper.run of SerpAPIWrapper(search_engine=<class 'serpapi.google_search.GoogleSearch'>, params={'engine': 'google', 'gl': 'uk', 'hl': 'en'}, serpapi_api_key='d38482db0efe9c48ec77ffdd165c3fb4d7144a6bf86b3604e4367b0a0fe17fdd', aiosession=None)>)]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e2d1108-81f4-4927-bbde-4e6d8685e043",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'llm': LlamaCpp(callbacks=<langchain.callbacks.manager.CallbackManager object at 0x0000021B14CC2160>, client=<llama_cpp.llama.Llama object at 0x0000021B14CC21C0>, model_path='llama-2-7b-chat.Q6_K.gguf', max_tokens=500000, temperature=0.1, top_p=0.9),\n",
       " 'factual_question_agent': {\n",
       "   input: RunnableLambda(...),\n",
       "   agent_scratchpad: RunnableLambda(...)\n",
       " }\n",
       " | PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'Bing: useful for when you need descriptive answers to questions about current state of affairs', 'tool_names': 'Bing'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       " | RunnableBinding(bound=LlamaCpp(callbacks=<langchain.callbacks.manager.CallbackManager object at 0x0000021B14CC2160>, client=<llama_cpp.llama.Llama object at 0x0000021B14CC21C0>, model_path='llama-2-7b-chat.Q6_K.gguf', max_tokens=500000, temperature=0.1, top_p=0.9), kwargs={'stop': ['\\nObservation']})\n",
       " | ReActSingleInputOutputParser(),\n",
       " 'agent_executor': AgentExecutor(verbose=True, agent=RunnableAgent(runnable={\n",
       "   input: RunnableLambda(...),\n",
       "   agent_scratchpad: RunnableLambda(...)\n",
       " }\n",
       " | PromptTemplate(input_variables=['agent_scratchpad', 'input'], partial_variables={'tools': 'Bing: useful for when you need descriptive answers to questions about current state of affairs', 'tool_names': 'Bing'}, template='Answer the following questions as best you can. You have access to the following tools:\\n\\n{tools}\\n\\nUse the following format:\\n\\nQuestion: the input question you must answer\\nThought: you should always think about what to do\\nAction: the action to take, should be one of [{tool_names}]\\nAction Input: the input to the action\\nObservation: the result of the action\\n... (this Thought/Action/Action Input/Observation can repeat N times)\\nThought: I now know the final answer\\nFinal Answer: the final answer to the original input question\\n\\nBegin!\\n\\nQuestion: {input}\\nThought:{agent_scratchpad}')\n",
       " | RunnableBinding(bound=LlamaCpp(callbacks=<langchain.callbacks.manager.CallbackManager object at 0x0000021B14CC2160>, client=<llama_cpp.llama.Llama object at 0x0000021B14CC21C0>, model_path='llama-2-7b-chat.Q6_K.gguf', max_tokens=500000, temperature=0.1, top_p=0.9), kwargs={'stop': ['\\nObservation']})\n",
       " | ReActSingleInputOutputParser()), tools=[Tool(name='Bing', description='useful for when you need descriptive answers to questions about current state of affairs', func=<bound method BingSearchAPIWrapper.run of BingSearchAPIWrapper(bing_subscription_key='02fa2d164e534dd69f2a586caba57cb6', bing_search_url='https://api.bing.microsoft.com/v7.0/search', k=10)>)])}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfa.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d6d145b-af36-421e-b098-d54e0ac69aa6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llm",
   "language": "python",
   "name": "llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
