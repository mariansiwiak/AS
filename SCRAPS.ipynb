{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "decab7a8-124f-4ff4-be37-9ed29b5a78bc",
   "metadata": {},
   "source": [
    "# Llama communication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c9f83b83-a01e-4793-85c7-180903bdb272",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "Exception ignored in: <function Llama.__del__ at 0x0000022D8408C790>\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\siwiak\\anaconda3\\envs\\agi\\lib\\site-packages\\llama_cpp\\llama.py\", line 1602, in __del__\n",
      "    llama_cpp.llama_free_model(self.model)\n",
      "  File \"C:\\Users\\siwiak\\anaconda3\\envs\\agi\\lib\\site-packages\\llama_cpp\\llama_cpp.py\", line 443, in llama_free_model\n",
      "    return _lib.llama_free_model(model)\n",
      "KeyboardInterrupt: \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'chain_1st' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[47], line 66\u001b[0m\n\u001b[0;32m     64\u001b[0m action_result \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mThe war continues\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     65\u001b[0m user_input_nth \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThis is the result of your previous action: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00maction_result\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m. Please continue your line of thought.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m---> 66\u001b[0m result_nth \u001b[38;5;241m=\u001b[39m \u001b[43mchain_1st\u001b[49m\u001b[38;5;241m.\u001b[39minvoke({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mprevious_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m: prompt_1st, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124msystem_prompt\u001b[39m\u001b[38;5;124m'\u001b[39m: system_prompt, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124muser_message\u001b[39m\u001b[38;5;124m'\u001b[39m: user_input})\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_iteration\u001b[39m(is_first_iteration, user_input, model_answer\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, previous_prompt\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m     69\u001b[0m     \u001b[38;5;66;03m# Define the prompt template based on whether it's the first iteration or not\u001b[39;00m\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m is_first_iteration:\n",
      "\u001b[1;31mNameError\u001b[0m: name 'chain_1st' is not defined"
     ]
    }
   ],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "def add_tools_to_system_prompt(tools):\n",
    "    tool_description_s = \"\\n\".join(\n",
    "        [f\"{index + 1}. Tool name (Action): {tool.name}; {tool.description}\" \n",
    "         for index, tool in enumerate(tools)]\n",
    "    )\n",
    "    tool_names_s = \"[\" + \", \".join([tool.name for tool in tools]) + \"]\"\n",
    "\n",
    "    system_prompt_template = \"\"\"Hi, we will engage in an iterative, multi-step communication.\n",
    "You will be able to utilize external tools as needed for enhanced interaction.\n",
    "Available tools: %s\n",
    "For your answers, you MUST use one of the two versions of the format! Do not provide any additional comments.\n",
    "Version 1: You MUST use it if you consider that your answer will be better if additional information is acquired or processed. \n",
    "1. Discussed issue: Write here the central topic of the conversation.\n",
    "2. Line of thinking: Present your line of thinking and the steps you will take in the following iterations.\n",
    "3. Action: Select one tool from %s IMPORTANT: Here, you must provide just a single word, the tool's name!\n",
    "4. Action Input: Provide input for the tool (e.g., the search query for the 'Internet' tool). IMPORTANT: Please provide just the input to be used without any commentary! \n",
    "5. Observations so far: Summarize and critically analyze the information gathered.\n",
    "You will receive the results of your information-gathering action for the next iteration.\n",
    "Version 2: Use it EXCLUSIVELY when you are sure that you have all the required information to formulate the final opinion on the discussed topic: \n",
    "1. Discussed issue: Write here the central topic of the conversation.\n",
    "2. Final thought (You must use this keyword ONLY when you complete your analysis after the last internal iteration!): \n",
    "Craft a comprehensive, insightful communicative output.\"\"\"%(f\"{tool_description_s}\", f\"{tool_names_s}.\")\n",
    "\n",
    "    return system_prompt_template\n",
    "\n",
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key='d38482db0efe9c48ec77ffdd165c3fb4d7144a6bf86b3604e4367b0a0fe17fdd')\n",
    "search_tool = Tool(\n",
    "    name=\"Internet\",\n",
    "    func=search.run,\n",
    "    description=\"Tool purpose: Search web for e.g., current events and state of affairs.; Tool syntax (Action Input): your_search_query.\"\n",
    ")\n",
    "fake_tool = Tool(\n",
    "    name=\"Fake\",\n",
    "    func=search.run,\n",
    "    description=\"Tool purpose: It serves not other purpose than to confuse.; Tool syntax (Action Input): Whatever, it doesn't do anything anyway.\"\n",
    ")\n",
    "tools = [search_tool, fake_tool]\n",
    "\n",
    "system_prompt = add_tools_to_system_prompt(tools)\n",
    "\n",
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-13b-chat.Q6_K.gguf\",\n",
    "    max_tokens=4096,\n",
    "    n_ctx=1024,\n",
    "    n_batch=16)\n",
    "\n",
    "llama_first_prompt = \\\n",
    "\"\"\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_message} [/INST]\"\"\"\n",
    "llama_first_prompt_template = PromptTemplate.from_template(llama_first_prompt)\n",
    "llama_next_prompt = \\\n",
    "\"\"\"{previous_prompt} {model_answer} </s><s>[INST] {user_input} [/INST] \"\"\"\n",
    "llama_next_prompt_template = PromptTemplate.from_template(llama_next_prompt)\n",
    "\n",
    "user_input_1st = \"What is the lastest news on Israel-Plaestine conflict?\"\n",
    "\n",
    "action_result = 'The war continues'\n",
    "user_input_nth = f\"This is the result of your previous action: {action_result}. Please continue your line of thought.\"\n",
    "result_nth = chain_1st.invoke({'previous_prompt': prompt_1st, 'system_prompt': system_prompt, 'user_message': user_input})\n",
    "\n",
    "def run_iteration(is_first_iteration, user_input, model_answer=None, previous_prompt=None):\n",
    "    # Define the prompt template based on whether it's the first iteration or not\n",
    "    if is_first_iteration:\n",
    "        prompt_template = llama_first_prompt_template\n",
    "        prompt_data = {'system_prompt': system_prompt, 'user_message': user_input}\n",
    "    else:\n",
    "        prompt_template = llama_next_prompt_template\n",
    "        prompt_data = {'previous_prompt': previous_prompt, 'model_answer': model_answer, 'user_message': user_input}\n",
    "\n",
    "    # Invoke the chain with the appropriate prompt\n",
    "    result = (prompt_template | llm).invoke(prompt_data)\n",
    "\n",
    "    # Extract the prompt for the next iteration\n",
    "    new_prompt = prompt_template.invoke(prompt_data)\n",
    "\n",
    "    return result, new_prompt\n",
    "\n",
    "user_input = \"What is the latest news on the Israel-Palestine conflict?\"\n",
    "result_1st, prompt_1st = run_iteration(True, user_input)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "118cf9e9-0969-4545-9189-b67885e04da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "108f73b4-b545-4ca8-ac87-d87278189260",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_tools_to_system_prompt(tools):\n",
    "    tool_description_s = \"\\n\".join(\n",
    "        [f\"{index + 1}. Tool name (Action): {tool.name}; {tool.description}\" \n",
    "         for index, tool in enumerate(tools)]\n",
    "    )\n",
    "    tool_names_s = \"[\" + \", \".join([tool.name for tool in tools]) + \"]\"\n",
    "\n",
    "    system_prompt_template = \"\"\"\n",
    "\"Welcome to our streamlined conversation. \n",
    "Your goal is to provide remarks that are direct, concise, and structured for easy processing. \n",
    "If the question is complex or outside your current knowledge, then you may use the following tools to gather more information: %s\n",
    "\n",
    "Assess the nature of each question and respond as follows:\n",
    "A. If a question is complex and requires tool usage:\n",
    "1. Line of Thought: Briefly outline your reasoning.\n",
    "2. Next Action: Clearly state the next step, using only the name of the tool from the list: %s\n",
    "3. Action Input: Provide the specific input for the tool, like a search query, without extra details.\n",
    "\n",
    "B. For straightforward questions or when enough information is available:\n",
    "1. Discussed issue: Identify the main topic.\n",
    "2. Final Answer (use this term): Give a concise, conclusive response.\n",
    "\n",
    "Remember, not every question demands in-depth analysis or external tools. \n",
    "Aim for brevity and precision in your answers, \n",
    "ensuring they're easily processable for future steps.\n",
    "\"\"\"%(f\"{tool_description_s}\", f\"{tool_names_s}\")\n",
    "\n",
    "    return system_prompt_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4e4e406-bc49-42a7-88f3-d45b925e2739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.utilities import SerpAPIWrapper\n",
    "from langchain.tools import Tool\n",
    "\n",
    "search = SerpAPIWrapper(serpapi_api_key='d38482db0efe9c48ec77ffdd165c3fb4d7144a6bf86b3604e4367b0a0fe17fdd')\n",
    "search_tool = Tool(\n",
    "    name=\"Internet\",\n",
    "    func=search.run,\n",
    "    description=\"Tool purpose: Search web for e.g., current events and state of affairs.; Tool syntax (Action Input): your_search_query.\"\n",
    ")\n",
    "fake_tool = Tool(\n",
    "    name=\"Fake\",\n",
    "    func=search.run,\n",
    "    description=\"Tool purpose: It serves not other purpose than to confuse.; Tool syntax (Action Input): Whatever, it doesn't do anything anyway.\"\n",
    ")\n",
    "tools = [search_tool, fake_tool]\n",
    "\n",
    "system_prompt = add_tools_to_system_prompt(tools)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d2f55051-6040-4e01-bb1a-50f1fbbc5dfc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(\n",
    "    model_path=\"llama-2-70b-chat.Q4_K_M.gguf\",\n",
    "    max_tokens=4096,\n",
    "    n_ctx=1024,\n",
    "    n_batch=16)\n",
    "\n",
    "llama_first_prompt = \\\n",
    "\"\"\"<s>[INST] <<SYS>>\\n{system_prompt}\\n<</SYS>>\\n\\n{user_message} [/INST]\"\"\"\n",
    "llama_first_prompt_template = PromptTemplate.from_template(llama_first_prompt)\n",
    "user_input_1st = \"What is the capital city of France?\"\n",
    "result_1st = (llama_first_prompt_template | llm).invoke({'system_prompt':system_prompt, 'user_message':user_input_1st})\n",
    "#prompt_1st = llama_first_prompt_template.invoke({'system_prompt':system_prompt, 'user_message':user_input})\n",
    "\n",
    "\n",
    "#llama_next_prompt = \\\n",
    "#\"\"\"{previous_prompt} {model_answer} </s><s>[INST] {user_input} [/INST] \"\"\"\n",
    "#llama_next_prompt_template = PromptTemplate.from_template(llama_next_prompt)\n",
    "#chain_nth = (llama_next_prompt_template | llm)\n",
    "#result_nth = chain_1st.invoke({'previous_prompt': prompt_1st 'model_answer': model_answer, 'user_message': user_input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "815b7ecd-8931-4c82-9dc6-2a8e69e7e33f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'  B. Discussed issue: Capital city of France\\nFinal Answer: Paris'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result_1st"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "163d0c00-25d1-45aa-b8f5-2d7c941b938e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c98983c-98ec-4dfb-9b5d-162f80865374",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff0cfd9-e33d-4cdd-b85e-d74d288c67c7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "4f919e8b-b57d-4902-a7be-2b58ce0a90e8",
   "metadata": {},
   "source": [
    "# Output parsing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9c603401-5c40-4aff-b496-79328f2246f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Critical role and challenges.\n",
      "Discussion Topic: Climate Change\n",
      "  Iteration 1:\n",
      "    Discussed issue: Climate change effects on agriculture.\n",
      "    Line of thinking: Research data.\n",
      "    Action: Internet.\n",
      "    Action Input: Search for recent data.\n",
      "    Observations so far: Significant impacts observed.\n",
      "    Action result: Found relevant data on climate impact.\n",
      "\n",
      "Discussion Topic: Education\n",
      "  Iteration 1:\n",
      "    Discussed issue: Technology in education.\n",
      "    Final thought: Critical role and challenges.\n"
     ]
    }
   ],
   "source": [
    "class ConversationStorage:\n",
    "    def __init__(self, cognitive_feedback_router_instance):\n",
    "        # Store conversation data with discussion topic as the main key\n",
    "        self.conversation_data = defaultdict(lambda: defaultdict(dict))\n",
    "        self.conversation_history = []\n",
    "        self.cognitive_feedback_router = cognitive_feedback_router_instance\n",
    "    \n",
    "    def update_conversation(self, discussion_topic, iteration_text):\n",
    "        # Parse the current iteration\n",
    "        parsed_iteration = self.flexible_parse_iteration(iteration_text)\n",
    "        # Determine the iteration number for the current topic\n",
    "        iteration_number = len(self.conversation_data[discussion_topic]) + 1\n",
    "        \n",
    "        # Add the parsed iteration to the conversation data\n",
    "        self.conversation_data[discussion_topic][iteration_number] = parsed_iteration\n",
    "        \n",
    "        # Add the raw text to the conversation history\n",
    "        self.conversation_history.append(iteration_text)\n",
    "\n",
    "        # Decide the action based on parsed data\n",
    "        if \"Action\" in parsed_iteration and \"Action Input\" in parsed_iteration:\n",
    "            # Call TakeAction's reaction method\n",
    "            TakeAction.reaction(parsed_iteration[\"Action\"], parsed_iteration[\"Action Input\"])\n",
    "        elif \"Final thought\" in parsed_iteration:\n",
    "            print(parsed_iteration[\"Final thought\"])\n",
    "            # Pass to CognitiveFeedbackRouter's display method\n",
    "            self.cognitive_feedback_router.display(parsed_iteration[\"Final thought\"])\n",
    "            # Send the entire agent_scratchpad to NeuralGraphBridge\n",
    "            NeuralGraphBridge.conversation(self.format_for_scratchpad())\n",
    "    \n",
    "    def add_result(self, discussion_topic, result):\n",
    "        # Identify the highest iteration number for the given discussion topic\n",
    "        if discussion_topic in self.conversation_data:\n",
    "            highest_iteration = max(self.conversation_data[discussion_topic])\n",
    "            # Add the result to the latest iteration of the given discussion topic\n",
    "            self.conversation_data[discussion_topic][highest_iteration]['Action result'] = result\n",
    "        else:\n",
    "            # If the topic is not found, this function does nothing (or you can handle it differently)\n",
    "            pass\n",
    "\n",
    "    def format_for_scratchpad(self):\n",
    "        scratchpad_text = \"\"\n",
    "        for topic, iterations in self.conversation_data.items():\n",
    "            scratchpad_text += f\"Discussion Topic: {topic}\\n\"\n",
    "            for iteration, data in iterations.items():\n",
    "                scratchpad_text += f\"  Iteration {iteration}:\\n\"\n",
    "                for key, value in data.items():\n",
    "                    scratchpad_text += f\"    {key}: {value}\\n\"\n",
    "            scratchpad_text += \"\\n\"\n",
    "        return scratchpad_text.strip()\n",
    "\n",
    "    @staticmethod\n",
    "    def flexible_parse_iteration(iteration_text):\n",
    "        # Labels to look for\n",
    "        labels = [\"Discussed issue\", \"Line of thinking\", \"Action\", \"Action Input\", \"Observations so far\", \"Final thought\"]\n",
    "\n",
    "        # Initialize a dictionary to store the parsed data for this iteration\n",
    "        agent_scratchpad = {}\n",
    "\n",
    "        # Process each label\n",
    "        for label in labels:\n",
    "            # Find the element text using regex, capturing until the next label or the end of the iteration\n",
    "            pattern = f\"{label}: ([\\\\s\\\\S]*?)(?=(\" + \"|\".join(labels) + \"|$))\"\n",
    "            match = re.search(pattern, iteration_text)\n",
    "\n",
    "            if match:\n",
    "                agent_scratchpad[label] = match.group(1).strip()\n",
    "            else:\n",
    "                # If the label is not found, check if its content might be under a different label\n",
    "                for alt_label in labels:\n",
    "                    if alt_label != label and alt_label in agent_scratchpad:\n",
    "                        # Check if the content for the alt_label seems to mistakenly include the content for the current label\n",
    "                        if f\"{label}:\" in agent_scratchpad[alt_label]:\n",
    "                            split_content = agent_scratchpad[alt_label].split(f\"{label}:\")\n",
    "                            # Assume the first part is for the alt_label and the second part (if exists) is for the current label\n",
    "                            agent_scratchpad[alt_label] = split_content[0].strip()\n",
    "                            if len(split_content) > 1:\n",
    "                                agent_scratchpad[label] = split_content[1].strip()\n",
    "                                break\n",
    "\n",
    "        return agent_scratchpad\n",
    "\n",
    "\n",
    "# Assuming TakeAction, CognitiveFeedbackRouter, and NeuralGraphBridge are defined elsewhere\n",
    "class TakeAction:\n",
    "    @staticmethod\n",
    "    def reaction(action, action_input):\n",
    "        # Implementation of the reaction method\n",
    "        pass\n",
    "\n",
    "class CognitiveFeedbackRouter:\n",
    "    def display(self, final_thought):\n",
    "        # Implementation of the display method\n",
    "        pass\n",
    "\n",
    "class NeuralGraphBridge:\n",
    "    @staticmethod\n",
    "    def conversation(agent_scratchpad):\n",
    "        # Implementation of the conversation method\n",
    "        pass\n",
    "\n",
    "# Example instantiation of CognitiveFeedbackRouter and ConversationStorage\n",
    "cognitive_feedback_router_instance = CognitiveFeedbackRouter()\n",
    "\n",
    "# Example usage\n",
    "conversation_store = ConversationStorage(cognitive_feedback_router_instance)\n",
    "\n",
    "# Simulate adding iterations to the conversation\n",
    "conversation_store.update_conversation(\"Climate Change\", \"Discussed issue: Climate change effects on agriculture. Line of thinking: Research data. Action: Internet. Action Input: Search for recent data. Observations so far: Significant impacts observed.\")\n",
    "conversation_store.add_result(\"Climate Change\", \"Found relevant data on climate impact.\")\n",
    "conversation_store.update_conversation(\"Education\", \"Discussed issue: Technology in education. Final thought: Critical role and challenges.\")\n",
    "\n",
    "# Format the conversation for the scratchpad\n",
    "scratchpad_formatted = conversation_store.format_for_scratchpad()\n",
    "print(scratchpad_formatted)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b35e2ac-f598-4a29-af10-520007bf6e59",
   "metadata": {},
   "source": [
    "# Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bb74e4ac-7267-4932-b932-e2cbce1cd37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs import Neo4jGraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b60662be-4d84-434a-aed0-5696b0c8cb6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = Neo4jGraph(\n",
    "    url=\"bolt://localhost:7687\", \n",
    "    username=\"neo4j\", \n",
    "    password=\"Ne5Invoces\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "f9f06090-2285-4af3-97ee-d19192974675",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.query(\n",
    "\"\"\"\n",
    "MERGE (m:Movie {name:\"Top Gun\"})\n",
    "WITH m\n",
    "UNWIND [\"Tom Cruise\", \"Val Kilmer\", \"Anthony Edwards\", \"Meg Ryan\"] AS actor\n",
    "MERGE (a:Actor {name:actor})\n",
    "MERGE (a)-[:ACTED_IN]->(m)\n",
    "\"\"\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "685b6504-eda0-4b8c-a305-25fea7dbd80d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "        Node properties are the following:\n",
      "        [{'labels': 'Professor', 'properties': [{'property': 'name', 'type': 'STRING'}, {'property': 'department', 'type': 'STRING'}]}, {'labels': 'Student', 'properties': [{'property': 'name', 'type': 'STRING'}, {'property': 'major', 'type': 'STRING'}]}, {'labels': 'Course', 'properties': [{'property': 'code', 'type': 'STRING'}, {'property': 'name', 'type': 'STRING'}]}, {'labels': 'Movie', 'properties': [{'property': 'name', 'type': 'STRING'}]}, {'labels': 'Actor', 'properties': [{'property': 'name', 'type': 'STRING'}]}]\n",
      "        Relationship properties are the following:\n",
      "        []\n",
      "        The relationships are the following:\n",
      "        ['(:Professor)-[:TEACHES]->(:Course)', '(:Student)-[:ENROLLED_IN]->(:Course)', '(:Actor)-[:ACTED_IN]->(:Movie)']\n",
      "        \n"
     ]
    }
   ],
   "source": [
    "graph.refresh_schema()\n",
    "print(graph.schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "a68824ec-460b-43a6-9810-69adb075b728",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mappingproxy({'__module__': 'langchain.graphs.neo4j_graph',\n",
       "              '__doc__': 'Neo4j wrapper for graph operations.\\n\\n    *Security note*: Make sure that the database connection uses credentials\\n        that are narrowly-scoped to only include necessary permissions.\\n        Failure to do so may result in data corruption or loss, since the calling\\n        code may attempt commands that would result in deletion, mutation\\n        of data if appropriately prompted or reading sensitive data if such\\n        data is present in the database.\\n        The best way to guard against such negative outcomes is to (as appropriate)\\n        limit the permissions granted to the credentials used with this tool.\\n\\n        See https://python.langchain.com/docs/security for more information.\\n    ',\n",
       "              '__init__': <function langchain.graphs.neo4j_graph.Neo4jGraph.__init__(self, url: Union[str, NoneType] = None, username: Union[str, NoneType] = None, password: Union[str, NoneType] = None, database: str = 'neo4j') -> None>,\n",
       "              'get_schema': <property at 0x1998f731860>,\n",
       "              'get_structured_schema': <property at 0x1998f7318b0>,\n",
       "              'query': <function langchain.graphs.neo4j_graph.Neo4jGraph.query(self, query: str, params: dict = {}) -> List[Dict[str, Any]]>,\n",
       "              'refresh_schema': <function langchain.graphs.neo4j_graph.Neo4jGraph.refresh_schema(self) -> None>,\n",
       "              'add_graph_documents': <function langchain.graphs.neo4j_graph.Neo4jGraph.add_graph_documents(self, graph_documents: List[langchain.graphs.graph_document.GraphDocument], include_source: bool = False) -> None>})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Neo4jGraph.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "eea2add1-27ce-4665-9028-c26b8255ea2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.graphs.graph_document import Node, Relationship, GraphDocument\n",
    "from langchain.schema import Document\n",
    "\n",
    "def create_graph_document_from_dict(data_dict):\n",
    "    # Create Node objects from 'nodes' in the dictionary\n",
    "    nodes = [Node(id=node_id, properties=props) for node_id, props in data_dict['nodes'].items()]\n",
    "\n",
    "    # Create a dictionary for quick node lookup by ID\n",
    "    nodes_lookup = {node.id: node for node in nodes}\n",
    "\n",
    "    # Create Relationship objects from 'edges' in the dictionary\n",
    "    edges = []\n",
    "    for (source_id, target_id), edge_info in data_dict['edges'].items():\n",
    "        # Check if both nodes exist\n",
    "        if source_id in nodes_lookup and target_id in nodes_lookup:\n",
    "            relationship_type = edge_info.pop('type', 'RELATES_TO')  # Extract the 'type'\n",
    "            edge = Relationship(\n",
    "                source=nodes_lookup[source_id], \n",
    "                target=nodes_lookup[target_id], \n",
    "                type=relationship_type, \n",
    "                properties=edge_info\n",
    "            )\n",
    "            edges.append(edge)\n",
    "\n",
    "    # Extract 'page_content' and 'metadata' for the Document object\n",
    "    page_content = data_dict['metadata'].pop('page_content', '')\n",
    "    metadata = data_dict['metadata']\n",
    "\n",
    "    # Create a Document object\n",
    "    source_document = Document(\n",
    "        page_content=page_content,\n",
    "        metadata=metadata\n",
    "    )\n",
    "\n",
    "    # Create and return a GraphDocument object\n",
    "    return GraphDocument(\n",
    "        nodes=nodes,\n",
    "        relationships=edges,\n",
    "        source=source_document\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "4eb43735-8423-4ecc-afd8-2e0cdf9072fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_document = create_graph_document_from_dict(example_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "9047563e-9de8-4fb6-b613-a03fdcbe4129",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GraphDocument(nodes=[Node(id='node_name1', properties={'name_parameter1': 'parameter1_value', 'name_parameter2': 'parameter2_value'}), Node(id='node_name2', properties={'name_parameter1': 'parameter1_value', 'name_parameter3': 'parameter3_value'})], relationships=[Relationship(source=Node(id='node_name1', properties={'name_parameter1': 'parameter1_value', 'name_parameter2': 'parameter2_value'}), target=Node(id='node_name2', properties={'name_parameter1': 'parameter1_value', 'name_parameter3': 'parameter3_value'}), type='RELATES_TO', properties={'name_parameter4': 'parameter4_value', 'name_parameter6': 'parameter2_value'})], source=Document(page_content='', metadata={'date': 'Some date', 'Interactee': 'Person', 'Tone': 'Somber', 'Urgency': 'Low'}))"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph_document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "80cfeaaa-4d90-4f2b-8dbc-277a2abcc62d",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph.add_graph_documents(graph_documents=[graph_document], include_source=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
