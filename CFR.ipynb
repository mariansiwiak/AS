{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4d881d3-c7d8-483d-b9e7-facd3aa787cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "\n",
    "import asyncio\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()\n",
    "\n",
    "from abc import ABC, abstractmethod\n",
    "\n",
    "from datetime import datetime\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "import shutil\n",
    "import glob\n",
    "import subprocess\n",
    "\n",
    "import logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "336f6807-a53e-4844-bdbc-db27e5c5c298",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_custom_log_levels():\n",
    "    # Define custom logging levels\n",
    "    MURMUR_LEVEL_NUM = 39\n",
    "    logging.addLevelName(MURMUR_LEVEL_NUM, \"MURMUR\")\n",
    "    def log_murmur(self, message, *args, **kwargs):\n",
    "        \"\"\" \n",
    "        Logging of CCM actions.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.isEnabledFor(MURMUR_LEVEL_NUM):\n",
    "            self._log(MURMUR_LEVEL_NUM, message, args, **kwargs)\n",
    "    logging.Logger.murmur = log_murmur\n",
    "\n",
    "    FLAG_LEVEL_NUM = 13\n",
    "    logging.addLevelName(FLAG_LEVEL_NUM, \"FLAG\")\n",
    "    def log_flag(self, message, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Logging of status flags statuses.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.isEnabledFor(FLAG_LEVEL_NUM):\n",
    "            self._log(FLAG_LEVEL_NUM, message, args, **kwargs)\n",
    "    logging.Logger.flag = log_flag\n",
    "\n",
    "    PROMPTING_LEVEL_NUM = 8\n",
    "    logging.addLevelName(PROMPTING_LEVEL_NUM, \"PROMPTING\")\n",
    "    def log_prompting(self, message, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Logging of complete prompt messages sent to CCM. \n",
    "        \"\"\"\n",
    "        \n",
    "        if self.isEnabledFor(PROMPTING_LEVEL_NUM):\n",
    "            self._log(PROMPTING_LEVEL_NUM, message, args, **kwargs)\n",
    "    logging.Logger.prompt = log_prompting\n",
    "\n",
    "    MONOLOGUE_LEVEL_NUM = 7\n",
    "    logging.addLevelName(MONOLOGUE_LEVEL_NUM, \"MONOLOGUE\")\n",
    "    def log_monologue(self, message, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        Logging of CCM internal monologue.\n",
    "        \"\"\"\n",
    "        \n",
    "        if self.isEnabledFor(MONOLOGUE_LEVEL_NUM):\n",
    "            self._log(MONOLOGUE_LEVEL_NUM, message, args, **kwargs)\n",
    "    logging.Logger.monologue = log_monologue\n",
    "\n",
    "def setup_logging(log_level: int = 7):\n",
    "    setup_custom_log_levels()\n",
    "\n",
    "    # Create a file handler for logging\n",
    "    log_directory = \"console\"\n",
    "    if not os.path.exists(log_directory):\n",
    "        os.makedirs(log_directory)\n",
    "\n",
    "    current_time = datetime.now().strftime(\"%Y%m%d_%H%M%S\")\n",
    "    log_file_name = f\"{log_directory}/file_{current_time}.log\"\n",
    "\n",
    "    file_handler = logging.FileHandler(log_file_name)\n",
    "    file_handler.setLevel(7)\n",
    "\n",
    "    console_handler = logging.StreamHandler()\n",
    "    console_handler.setLevel(log_level)\n",
    "\n",
    "    formatter = logging.Formatter('%(asctime)s - %(levelname)s - %(name)s - %(funcName)s - %(message)s')\n",
    "    file_handler.setFormatter(formatter)\n",
    "    console_handler.setFormatter(formatter)\n",
    "\n",
    "    root_logger = logging.getLogger()\n",
    "    root_logger.setLevel(7)  # Set the lowest overall level to log\n",
    "\n",
    "    # Clear existing handlers (if any), and then add new handlers\n",
    "    if root_logger.hasHandlers():\n",
    "        root_logger.handlers.clear()\n",
    "    root_logger.addHandler(file_handler)\n",
    "    root_logger.addHandler(console_handler)\n",
    "\n",
    "# Call the setup function\n",
    "setup_logging()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7639dc99-a78d-445b-9dc9-41e1bab80c8c",
   "metadata": {},
   "source": [
    "### Stem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c7eeff60-0d0a-46d2-935f-da4cc40889d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StemUtility:\n",
    "    \"\"\"\n",
    "    A class for managing and retrieving predefined prompts.\n",
    "\n",
    "    This class stores a collection of utility functions utilized by other system classes.\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def extract_keywords(raw_output):\n",
    "        \"\"\"\n",
    "        Extracts keywords from the summary output.\n",
    "\n",
    "        Args:\n",
    "            raw_output (str): The output from which to extract keywords.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of extracted keywords.\n",
    "        \"\"\"\n",
    "\n",
    "        # Regex pattern to find all occurrences of words flanked by **\n",
    "        pattern = r\"\\*\\*(.*?)\\*\\*\"\n",
    "        # Find all matches and strip the ** from each keyword\n",
    "        keywords = [keyword.lower() for keyword in re.findall(pattern, raw_output)]\n",
    "        return keywords\n",
    "\n",
    "    @staticmethod\n",
    "    def get_timestamp():\n",
    "        return datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "\n",
    "    @staticmethod\n",
    "    def archive(source_path: str, source_file: str | None = None, archive_suffix='archive'):\n",
    "        \"\"\"\n",
    "        Moves processed file to the respective archive folder.\n",
    "\n",
    "        Args:\n",
    "            source_path (str): The source folder\n",
    "            source_file (str): The file to be archived\n",
    "\n",
    "        Returns:\n",
    "            bool: Information if the process has been successful\n",
    "        \"\"\"\n",
    "\n",
    "        if not source_file:\n",
    "            source_path, source_file = os.path.split(source_file)\n",
    "        \n",
    "        destination_path = '_'.join(source_path, archive_suffix)\n",
    "        \n",
    "        logger = logging.getLogger('StemUtility')        \n",
    "        try:\n",
    "            shutil.move(source_path, destination_path)\n",
    "            return True\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"File not found: {source_path}\")\n",
    "            return False\n",
    "        except PermissionError:\n",
    "            logger.error(f\"Permission denied: Cannot move {source_path} to {destination_path}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error moving file {source_path} to {destination_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def setup_directories(dir_path: str) -> bool:\n",
    "        \"\"\"\n",
    "        Check existence / creates the necessary directories.\n",
    "        Performs checks and ensures access problems won't cause overall program termination. \n",
    "\n",
    "        Args:\n",
    "            dir_path (str): Path to required folder\n",
    "\n",
    "        Returns: \n",
    "            bool: Information if the process has been successhul\n",
    "        \"\"\"\n",
    "\n",
    "        logger = logging.getLogger('StemUtility')\n",
    "        \n",
    "        try:\n",
    "            os.makedirs(dir_path, exist_ok=True)\n",
    "            logger.debug(f\"Checked / created folder: {dir_path}\")\n",
    "            return True\n",
    "        except PermissionError:\n",
    "            logger.error(f\"Permission denied: Unable to create or access folder {dir_path}.\")\n",
    "            return False\n",
    "        except OSError as e:\n",
    "            logger.error(f\"OS error when creating folder {dir_path}: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error creating folder {dir_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def memory_read(file_path: str, filetype: str = 'text') -> str:\n",
    "        \"\"\"Function for accessing files, mainly  related to the system memory.\n",
    "        Performs checks and ensures that lack of the file won't cause overall program termination. \n",
    "\n",
    "        Args: \n",
    "            file_path (str): Path to the file to be accessed\n",
    "            filetype (str): Type of the file to be read [json, text]\n",
    "\n",
    "        Returns:\n",
    "            file content\n",
    "        \"\"\"\n",
    "        \n",
    "        logger = logging.getLogger('StemUtility')\n",
    "        try:\n",
    "            with open(file_path, 'r') as file:\n",
    "                if filetype == 'json':\n",
    "                    data = json.load(file)\n",
    "                elif filetype == 'text':\n",
    "                    data = file.read()\n",
    "                else:\n",
    "                    logger.error(f\"Unkown file type: {filetype}\")\n",
    "                    return False\n",
    "                return data\n",
    "        except FileNotFoundError:\n",
    "            logger.error(f\"File not found: {file_path}\")\n",
    "            return False\n",
    "        except json.JSONDecodeError:\n",
    "            logger.error(f\"Error decoding JSON from the file: {file_path}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error reading file {file_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "    @staticmethod\n",
    "    def memory_write(file_path, file_content) -> None:\n",
    "        \"\"\"Function for accessing files, mainly  related to the system memory.\n",
    "        Performs checks and ensures that lack of the file won't cause overall program termination. \n",
    "\n",
    "        Args: \n",
    "            file_path (str): Path to the file to be accessed\n",
    "            filetype (str): Type of the file to be read [json, text]\n",
    "        \"\"\"\n",
    "\n",
    "        logger = logging.getLogger('StemUtility')\n",
    "        try:\n",
    "            with open(file_path, \"w\") as file:\n",
    "                file.write(file_content)\n",
    "        except PermissionError:\n",
    "            logger.error(f\"Permission denied: Unable to write to file {file_path}.\")\n",
    "        except OSError as e:\n",
    "            logger.error(f\"File system error when writing to file {file_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Unexpected error wrtiting to file {file_path}: {e}\")\n",
    "    \n",
    "    @staticmethod\n",
    "    def get_prompt(key):\n",
    "        \"\"\"\n",
    "        Retrieves a prompt template by its key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the prompt to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            str: The prompt template associated with the given key. If the key is not found,\n",
    "                 a default prompt text is returned.\n",
    "        \"\"\"\n",
    "\n",
    "        prompts = StemUtility.memory_read('conversations/prompts.json', 'json')\n",
    "        return prompts.get(key, \"\")\n",
    "\n",
    "    @staticmethod\n",
    "    def transplantation(base_model_path: str, new_model_path: str):\n",
    "        \"\"\"Function moving new, finetuned model in place of an old one.\n",
    "\n",
    "        Args:\n",
    "            base_model_path (str): Path to the original model file\n",
    "            new_model_path (str): Path to finetuned model\n",
    "        \n",
    "        \"\"\"\n",
    "        \n",
    "        try:\n",
    "            self.logger.debug(f\"Checking if {new_model_path} exists.\")\n",
    "            if not os.path.exists(new_model_path):\n",
    "                if os.path.exists(base_model_path):\n",
    "                    # new_model_path doesn't exist but base model does\n",
    "                    raise Exception(f\"No new model file found {new_model_path}.\")\n",
    "                else:\n",
    "                    raise Exception(f\"Missing both model files: {base_model_path} and {new_model_path}\")\n",
    "\n",
    "            backup_path = base_model_path + \"_bck\"\n",
    "            self.logger.debug(f\"Trying to backup old model file to {backup_path}.\")            \n",
    "            if os.path.exists(base_model_path):\n",
    "                try:\n",
    "                    shutil.copy(base_model_path, backup_path)\n",
    "                except Exception as e:\n",
    "                    raise Exception(f\"Warning: can't make a backup: {e}\") from e\n",
    "            \n",
    "            self.logger.debug(f\"Trying to remove original model file: {base_model_path}.\")                    \n",
    "            if os.path.exists(base_model_path):\n",
    "                os.remove(base_model_path)\n",
    "                if os.path.exists(base_model_path):\n",
    "                    raise Exception(\"Failed to remove the existing model file.\")\n",
    "        \n",
    "            self.logger.debug(f\"Trying to move new model file {new_model_path} to take place of {base_model_path}.\")                    \n",
    "            shutil.move(new_model_path, base_model_path)\n",
    "            if not os.path.exists(base_model_path):\n",
    "                raise Exception(f\"Failed to swap LLM model files.\")\n",
    "        \n",
    "            self.logger.info(\"Base LLM File swap successful.\")\n",
    "\n",
    "        except Exception as e:\n",
    "            # Update the error logging to handle general exceptions, not just subprocess-related ones\n",
    "            self.logger.error(f\"Self brain transplantation failed: {str(e)}\")\n",
    "            # Reraise the exception with a custom message\n",
    "            raise Exception(f\"At least we tried... {e}\") from e "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35338185-3632-4ea2-9309-153a30876e00",
   "metadata": {},
   "source": [
    "### Short-Term Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8d50a8d8-f4ad-4ded-8305-f646d2aafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortTermMemory:\n",
    "    \"\"\"\n",
    "    A class to manage a short-term memory storage system for conversations.\n",
    "\n",
    "    This class handles the storage, retrieval, and management of conversations\n",
    "    linked to specific keywords. The conversations are stored as file paths in a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, stm_path: str = 'conversations/short-term-memory.json'):\n",
    "        \"\"\"\n",
    "        Initializes the ShortTermMemory class by setting up the JSON file for storage.\n",
    "\n",
    "        This method checks if the JSON file exists at the specified location and creates it if not.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.debug(f\"Instantiating {self.__class__.__name__} with Short Term Memory path: {stm_path}\")\n",
    "        \n",
    "        self._stm_path = stm_path\n",
    "        if not os.path.exists(self._stm_path):\n",
    "            with open(self._stm_path, 'w') as file:\n",
    "                json.dump({}, file)\n",
    "\n",
    "    def memorize(self, keywords: list, filename: str) -> None:\n",
    "        \"\"\"\n",
    "        Memorizes a conversation file under given keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to associate with the conversation file.\n",
    "            filename (str): The name of the file containing the conversation.\n",
    "\n",
    "        This method updates the JSON storage with the filename under each provided keyword.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.debug(f\"Saving keywords: {keywords}, related to conversation from: {filename}.\")\n",
    "\n",
    "        with open(self._stm_path, 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            for keyword in keywords:\n",
    "                if keyword in data:\n",
    "                    if filename not in data[keyword]:\n",
    "                        data[keyword].append(filename)\n",
    "                else:\n",
    "                    data[keyword] = [filename]\n",
    "            file.seek(0)\n",
    "            json.dump(data, file, indent=4)\n",
    "            file.truncate()\n",
    "\n",
    "    def search_memories(self, keywords: list) -> list:\n",
    "        \"\"\"\n",
    "        Searches for conversation files associated with given keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to search for.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of filenames associated with any of the given keywords.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.debug(f\"Searching in {self._stm_path} for files related to keywords: {keywords}.\")\n",
    "\n",
    "\n",
    "        data = StemUtility.memory_read(self._stm_path, 'json')\n",
    "        if data: \n",
    "            self.logger.debug(f\"Loaded short term memory.\")\n",
    "        else:\n",
    "            data = {}\n",
    "        \n",
    "        filenames = set()\n",
    "        for keyword in keywords:\n",
    "            filenames.update(data.get(keyword, []))\n",
    "        return list(filenames)\n",
    "\n",
    "    def concatenate_memories(self, filenames: list) -> str:\n",
    "        \"\"\"\n",
    "        Concatenates the contents of conversation files.\n",
    "\n",
    "        Args:\n",
    "            filenames (list): A list of filenames to concatenate.\n",
    "\n",
    "        Returns:\n",
    "            str: A single string containing all the concatenated conversations.\n",
    "                 Each conversation is prefixed with its source and date.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.debug(f\"Concatenating selected conversations into one file.\")\n",
    "        \n",
    "        conversations = \"\"\n",
    "        for filename in filenames:\n",
    "            file_content = StemUtility.memory_read(filename)\n",
    "            date_str = re.search(r'conversation_(\\d{8})(\\d{6})\\.txt$', filename)\n",
    "            if date_str:\n",
    "                # Parse the date and time\n",
    "                date_time = datetime.strptime(date_str.group(1) + date_str.group(2), '%Y%m%d%H%M%S')\n",
    "                # Format the date and time\n",
    "                formatted_date = date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                conversations += f'Conversation from {formatted_date}\\n{file_content}\\n'\n",
    "            else:\n",
    "                conversations += f'Conversation from {filename}\\n{file_content}\\n'               \n",
    "        \n",
    "        return conversations\n",
    "\n",
    "    def forget_keywords(self, keywords_to_clear: list) -> None:\n",
    "        \"\"\"\n",
    "        Removes specified keywords and their associated conversations from memory.\n",
    "\n",
    "        Args:\n",
    "            keywords_to_clear (list): A list of keywords to remove from the memory.\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"Clearing {keywords_to_clear} from {self._stm_path}.\")\n",
    "\n",
    "        try:\n",
    "            with open(self._stm_path, 'r+') as file:\n",
    "                data = json.load(file)\n",
    "                for keyword in keywords_to_clear:\n",
    "                    if keyword in data:\n",
    "                        del data[keyword]\n",
    "                file.seek(0)\n",
    "                json.dump(data, file, indent=4)\n",
    "                file.truncate()\n",
    "            self.logger.debug(f\"Selected keywords removed from {self._stm_path}.\")\n",
    "            \n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File {self._stm_path} not found.\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Unexpected error reading file {self._stm_path}: {e}\")\n",
    "\n",
    "    def recall_all_keywords(self) -> list:\n",
    "        \"\"\"\n",
    "        Retrieves a list of all keywords stored in memory.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of all keywords.\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"Reading all keywords from {self._stm_path}.\")\n",
    "\n",
    "        data = StemUtility.memory_read(self._stm_path, 'json')\n",
    "        if data and len(data) > 0:\n",
    "            return list(data.keys())\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecbc8c33-3e50-499f-857c-9aaf021f6614",
   "metadata": {},
   "source": [
    "### Default Mode Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "49469e81-0f0f-4339-8bf3-67d175937d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultModeNetwork:\n",
    "    \"\"\"\n",
    "    A class designed to integrate a language learning model (LLM) with a short-term memory storage system.\n",
    "    This class enables the LLM to process and learn from saved conversation data autonomously.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 llm,\n",
    "                 overwhelmed_event,\n",
    "                 engaged_event,\n",
    "                 conclusions_storage_path: str = 'conclusions',\n",
    "                ):\n",
    "        \"\"\"\n",
    "        Initializes the DefaultModeNetwork class by setting up the short-term memory (STM) component.\n",
    "        \"\"\"\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.debug(f\"Instantiating {self.__class__.__name__} with conclusions_storage_path: {conclusions_storage_path}.\")\n",
    "        self.logger.flag(f\"overhelmed: {overwhelmed_event.is_set()}\") \n",
    "        \n",
    "        self.stm = ShortTermMemory()\n",
    "        self.llm = llm\n",
    "\n",
    "        self.overwhelmed = overwhelmed_event\n",
    "        self.engaged = engaged_event\n",
    "        \n",
    "        self._conclusions_storage_path = conclusions_storage_path\n",
    "        StemUtility.setup_directories(self._conclusions_storage_path)          \n",
    "\n",
    "        self._keyword_selection_prompt_template = StemUtility.get_prompt(\"keyword_selection\")\n",
    "        self._perspective_explanation_prompt_template = StemUtility.get_prompt(\"perspective_explanation\")\n",
    "    \n",
    "    \n",
    "    async def _interesting_keywords_selection(self, keywords) -> list:\n",
    "        \"\"\"\n",
    "        Asynchronously selects a subset of keywords deemed interesting or relevant by the LLM.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to choose from.\n",
    "\n",
    "        Returns:\n",
    "            list: A subset of selected keywords.\n",
    "        \"\"\"\n",
    "\n",
    "        keywords_selection_prompt = self._keyword_selection_prompt_template.replace(\"{keywords_list}\", ', '.join(keywords))\n",
    "        self.logger.prompt(f\"Interesting keyword selection prompt:\\n{keywords_selection_prompt}.\")        \n",
    "        self.logger.debug(f\"Asking LLM to select interesting keywords.\")   \n",
    "        keywords_selected_raw_output = self.llm(keywords_selection_prompt)\n",
    "        self.logger.monologue(f\"LLM selected interesting keywords:\\n{keywords_selected_raw_output}.\\nMoving to keywords extraction.\")   \n",
    "        keywords_selected_pure = StemUtility.extract_keywords(keywords_selected_raw_output)\n",
    "        self.logger.debug(f\"Interesting keywords found: {keywords_selected_pure}\")   \n",
    "        \n",
    "        return keywords_selected_pure\n",
    "\n",
    "    def _fetch_memory(self, keywords) -> str:\n",
    "        \"\"\"\n",
    "        Fetches and concatenates interaction history data based on the provided keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to search the interaction data for.\n",
    "\n",
    "        Returns:\n",
    "            str: A concatenated string of all interaction history files related to the given keywords.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.debug(f\"Reaching to Short Term memory for for all the files related to: {keywords}\")  \n",
    "        filenames = self.stm.search_memories(keywords)\n",
    "        self.logger.debug(f\"Ordering concatenation of identified files.\")          \n",
    "        concatenated_memories = self.stm.concatenate_memories(filenames)\n",
    "        return filenames, concatenated_memories \n",
    "\n",
    "    async def _analyze_interaction(self, interaction_history) -> str:\n",
    "        \"\"\"\n",
    "        Analyzes the concatenated interaction history.\n",
    "\n",
    "        Args:\n",
    "            conversations (str): The concatenated string of conversations to be analyzed.\n",
    "        \"\"\"\n",
    "    \n",
    "        perspective_explanation_prompt = self._perspective_explanation_prompt_template.replace(\"{interaction_history}\", \n",
    "                                                                                             interaction_history)\n",
    "        self.logger.prompt(f\"Prompt for conversation analysis:\\n{perspective_explanation_prompt}.\")\n",
    "        self.logger.murmur(f\"Thinking about recent conversations...\")   \n",
    "        adaptation_explanation = self.llm(perspective_explanation_prompt)\n",
    "        self.logger.monologue(f\"Full explanation of the required adaptation: {adaptation_explanation}\")   \n",
    "        return adaptation_explanation\n",
    "\n",
    "    async def ponder(self):\n",
    "        \"\"\"\n",
    "        The main asynchronous method of the class that orchestrates the process of \n",
    "        selecting keywords, fetching conversations, and analyzing them.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger.debug(f\"Checking if there are any topics to be analyzed deeper.\")           \n",
    "        all_keywords = self.stm.recall_all_keywords()\n",
    "        if not all_keywords:\n",
    "            self.logger.murmur(f\"Kingdom for a good book!\")   \n",
    "            return False\n",
    "\n",
    "        self.logger.debug(f\"All keywords: {all_keywords}. Moving to interesting keyword selection.\")           \n",
    "        interesting_keywords = await self._interesting_keywords_selection(all_keywords)\n",
    "        self.logger.debug(f\"Interesting keywords selected.\")           \n",
    "        memory_files, concatenated_memories = self._fetch_memory(interesting_keywords)\n",
    "        self.logger.debug(f\"Concatenated conversations received.\")   \n",
    "\n",
    "        # Assume an async version of LLM analysis\n",
    "        if concatenated_memories:\n",
    "            self.logger.debug(f\"Moving to analyze the conversaton histories.\")           \n",
    "            adaptation_summary = await self._analyze_interaction(concatenated_memories)\n",
    "            if \"uninspiring\" not in adaptation_summary.lower():\n",
    "                self.logger.murmur(f\"Discussion on {interesting_keywords} indeed brought a new perspective...\")\n",
    "                conclusion_path = os.path.join(self._conclusions_storage_path, f\"conclusion_{StemUtility.get_timestamp()}.txt\")\n",
    "                self.logger.debug(f\"Conclusions will be saved to {conclusion_path}.\")\n",
    "                StemUtility.memory_write(conclusion_path, adaptation_summary)\n",
    "                self.overwhelmed.set()\n",
    "                self.logger.flag(f\"overwhelmed: {self.overwhelmed.is_set()}\")\n",
    "            else:\n",
    "                self.logger.monologue(f\"As per:\\n{adaptation_summary}.\\nNothing interesting has been found in {memory_files}.\")\n",
    "                for memory_file in memory_files:\n",
    "                    StemUtility.archive(memory_file)\n",
    "        else:\n",
    "            self.logger.error(f\"Concatenated conversations turned out to be an empty string.\")   \n",
    "        self.logger.debug(f\"Interesting or not, forgetting conversations about {interesting_keywords}.\")   \n",
    "        self.stm.forget_keywords(interesting_keywords)\n",
    "        self.engaged.clear()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b57c7801-b36d-446b-b6e8-4f81ec89ad27",
   "metadata": {},
   "source": [
    "### REM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "19df4d7c-232a-4d0b-8bc3-632b186f3f35",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReflectiveEvolutionMonitor:\n",
    "    \"\"\"\n",
    "    A class designed to enable a language learning model (LLM) to self-reflect and evolve based on the conclusions drawn from user interactions.\n",
    "    The class uses the same LLM for reading summaries, preparing fine-tuning materials, and the fine-tuning process.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 llm,\n",
    "                 base_model_path: str = 'llama-2-13b-chat.Q6_K.gguf',\n",
    "                 conclusions_storage_path: str = 'conclusions',\n",
    "                 dream_storage_path: str = 'context',\n",
    "                 dreams_number: int = 72):\n",
    "        \"\"\"\n",
    "        Initializes the ReflectiveEvolutionMonitor class. \n",
    "\n",
    "        Arguments:\n",
    "            llm: Large Language Model used as a base of the system\n",
    "            base_model_path: path to 'llm' file on disk\n",
    "            conclusions_storage_path: path to folder containing not-permeated new perspectives\n",
    "            dream_storage_path: path to a folder to store finetune materials to be used in this session\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.debug(f\"Instantiating {self.__class__.__name__} with base_model_path = {base_model_path}, conclusions_storage_path = {conclusions_storage_path}, \\\n",
    "        dream_storage_path: {dream_storage_path}, dream_archive_path: {dream_archive_path}.\")  \n",
    "    \n",
    "        self.llm = llm\n",
    "        \n",
    "        self._base_model_path = base_model_path\n",
    "\n",
    "        self._conclusions_storage_path = conclusions_storage_path\n",
    "        StemUtility.setup_directories(self._conclusions_storage_path)        \n",
    "        StemUtility.setup_directories(self._conclusions_archive_path)\n",
    "        \n",
    "        self._dream_storage_path = dream_storage_path\n",
    "        StemUtility.setup_directories(self._dream_storage_path)        \n",
    "        StemUtility.setup_directories(self._dream_archive_path)        \n",
    "\n",
    "        self._dream_spinning_prompt_template = StemUtility.get_prompt(\"dream_spinning\")\n",
    "        self._dream_prompt_template = StemUtility.get_prompt(\"dream_template\")\n",
    "        \n",
    "        self._conclusions = ''\n",
    "        self._dreams_number = dreams_number        \n",
    "\n",
    "    def _gather_conclusion(self) -> bool:\n",
    "        \"\"\"\n",
    "        Reads a summary document as a text file.\n",
    "\n",
    "        Returns:\n",
    "            bool: True if the summary was successfully read, False otherwise.\n",
    "        \"\"\"\n",
    "\n",
    "        try:\n",
    "            # Use glob to list files that match the pattern \"conclusion*\"\n",
    "            conclusion_pattern = os.path.join(self._conclusions_storage_path, \"conclusion*\")\n",
    "            conclusion_files = glob.glob(conclusion_pattern)\n",
    "\n",
    "            if not conclusion_files:\n",
    "                self.logger.error(\"No conclusion files found matching the pattern.\")\n",
    "                return False\n",
    "\n",
    "            # Process the first file from the matched conclusion files\n",
    "            selected_file_name_path = conclusion_files[0]\n",
    "\n",
    "            with open(selected_file_name_path, 'r') as file:\n",
    "                self._conclusions = file.read()\n",
    "\n",
    "        except FileNotFoundError:\n",
    "            self.logger.error(f\"File not found: {selected_file_name_path}\")\n",
    "            return False\n",
    "        except OSError as e:\n",
    "            self.logger.error(f\"OS error reading file {selected_file_name_path}: {e}\")\n",
    "            return False\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Unexpected error reading file {selected_file_name_path}: {e}\")\n",
    "            return False\n",
    "\n",
    "        return True\n",
    "\n",
    "    async def _spin_dream(self, dream_prompt) -> str:\n",
    "        \"\"\"\n",
    "        Prepares a single piece of data required for the fine-tuning process by interpreting the summary content.\n",
    "\n",
    "        Args:\n",
    "            dream_prompt (str): Prompt to generate a single piece of training material.\n",
    "\n",
    "        Returns:\n",
    "            dict: Data structured for fine-tuning.\n",
    "        \"\"\"\n",
    "\n",
    "        dream_content = self.llm(dream_prompt)\n",
    "        self.logger.monologue(f\"I had a dream:\\n{dream_content}.\")\n",
    "        dream = self._dream_prompt_template.replace(\"{dream_content}\", dream_content) \n",
    "        return dream\n",
    "\n",
    "    \n",
    "    async def _weave_dreams(self, num_dreams) -> str:\n",
    "        \"\"\"\n",
    "        Generates a specified number of materials (dreams) and writes them into a single text file.\n",
    "        Each 'dream' is appended to the file as it is generated.\n",
    "\n",
    "        Args:\n",
    "            num_dreams (int): Number of training materials to be generated\n",
    "\n",
    "        Returns:\n",
    "            str: Concated training materials set\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.info(f\"Generating {num_dreams} dreams.\")\n",
    "        dreams_path = os.path.join(self._dream_storage_path, f\"dream_{StemUtility.get_timestamp()}.txt\")\n",
    "        self.logger.debug(f\"Dreams for this sessions will be saved to: {dreams_path}.\")        \n",
    "        dream_spinning_prompt = self._dream_spinning_prompt_template.replace(\"{adaptation_summary}\", self._conclusions) \n",
    "        self.logger.prompt(f\"Prompt for generating training material from conversation conclusions:\\n{dream_spinning_prompt}.\")   \n",
    "        \n",
    "        for i in range(num_dreams):\n",
    "            self.logger.info(f\"Generating dream # {i}.\")\n",
    "            dream = await self._spin_dream(dream_spinning_prompt)\n",
    "            with open(dreams_path, 'a') as file:  # Open and append each dream, then close the file\n",
    "                file.write(dream + '\\n')\n",
    "        return dreams_path\n",
    "\n",
    "    \n",
    "    async def _deepsleep(self, dreams_path: str) -> None:\n",
    "        \"\"\"\n",
    "        Executes the fine-tuning process using the prepared data.\n",
    "\n",
    "        Args:\n",
    "            fine_tuning_data (dict): Data prepared for fine-tuning.\n",
    "        \"\"\"\n",
    "        \n",
    "        llamacpp_folder = \"llama.cpp\"\n",
    "        finetune_tool = \"finetune.exe\"\n",
    "        lora_tool = \"export-lora.exe\"\n",
    "\n",
    "        finetune_tool_path = os.path.join(llamacpp_folder, finetune_tool)\n",
    "        lora_tool_path = os.path.join(llamacpp_folder, lora_tool)\n",
    "\n",
    "        # Check if finetune_tool_path is a valid file\n",
    "        if not os.path.isfile(finetune_tool_path):\n",
    "            raise FileNotFoundError(f\"Fine-tuning tool not found at {finetune_tool_path}\")\n",
    "\n",
    "        # Check if lora_tool_path is a valid file\n",
    "        if not os.path.isfile(lora_tool_path):\n",
    "            raise FileNotFoundError(f\"LoRA tool not found at {lora_tool_path}\")\n",
    "\n",
    "        \n",
    "        # Fine-tuning command\n",
    "        finetune_command = [\n",
    "            finetune_tool_path,\n",
    "            \"--model-base\", self._base_model_path,\n",
    "            \"--train-data\", dreams_path,\n",
    "            \"--threads\", \"16\",\n",
    "            \"--sample-start\", \"<s>\",\n",
    "            \"--epochs\", \"1\"\n",
    "        ]\n",
    "\n",
    "        self.logger.murmur(f\"Self-finetuning: Creating matrix\")\n",
    "        self.logger.debug(f\"Running command:\\n{finetune_command}.\")\n",
    "\n",
    "        try:\n",
    "            subprocess.run(finetune_command, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.logger.error(f\"Self-finetuning session failed the return code {e.returncode}.\")   \n",
    "            return False\n",
    "        \n",
    "        # Export LoRA model command - output to llm_tmp.guff\n",
    "        tmp_model_path = r\"llm_tmp.guff\"\n",
    "        export_command = [\n",
    "            lora_tool_path,\n",
    "            \"--model-base\", self._base_model_path,\n",
    "            \"--model-out\", tmp_model_path,\n",
    "            \"--lora-scaled\", r\".\\ggml-lora-LATEST-f32.gguf\",\n",
    "            \"0.7\"\n",
    "        ]\n",
    "\n",
    "        self.logger.murmur(f\"Self-finetuning: Merging weights\")\n",
    "        self.logger.debug(f\"Running command:\\n{export_command}.\")\n",
    "\n",
    "        try:\n",
    "            subprocess.run(export_command, check=True)\n",
    "        except subprocess.CalledProcessError as e:\n",
    "            self.logger.error(f\"LoRA merge failed with the return code {e.returncode}.\")   \n",
    "            return False        \n",
    "\n",
    "        self.logger.murmur(f\"Self-finetuning: Swapping brain to a new one\")\n",
    "        self.logger.info(f\"Removing old {self._base_model_path}, moving {tmp_model_path} as new {self._base_model_path}.\")\n",
    "        StemUtility.transplantation(self._base_model_path, tmp_model_path)\n",
    "    \n",
    "    def _dream_prunning(self):\n",
    "        \"\"\"\n",
    "        Archives dream materials by moving them from the dream storage path to the archive path.\n",
    "        \"\"\"\n",
    "        \n",
    "        self.logger.info(\"Archiving dream materials.\")\n",
    "        try:\n",
    "            for file_name in os.listdir(self._dream_storage_path):\n",
    "                source_path = os.path.join(self._dream_storage_path, file_name)\n",
    "                destination_path = os.path.join(self._dream_archive_path, file_name)\n",
    "                try:\n",
    "                    shutil.move(source_path, destination_path)\n",
    "                except FileNotFoundError:\n",
    "                    self.logger.error(f\"File not found: {source_path}\")\n",
    "                except PermissionError:\n",
    "                    self.logger.error(f\"Permission denied: Cannot move {source_path} to {destination_path}\")\n",
    "                except Exception as e:\n",
    "                    self.logger.error(f\"Error moving file {source_path} to {destination_path}: {e}\")\n",
    "        except Exception as e:\n",
    "            self.logger.error(f\"Error moving file {source_path} to {destination_path}: {e}\")\n",
    "\n",
    "    \n",
    "    async def dream(self):\n",
    "        \"\"\"\n",
    "        Orchestrates the whole process of selecting a summary, reading it, preparing fine-tuning data, and performing fine-tuning.\n",
    "        \"\"\"  \n",
    "\n",
    "        self.logger.murmur(f\"Closing eyes for a well-deserved nap.\")\n",
    "        self.logger.info(f\"Self-finetuning process started.\")        \n",
    "\n",
    "        conclusions_found = self._gather_conclusion()        \n",
    "        if not conclusions_found:\n",
    "            return False\n",
    "        self.logger.info(f\"Selected conclusion to permeate.\")\n",
    "        dreams_path = await self._weave_dreams(self._dreams_number)  # Generate 50 materials, modify as needed\n",
    "        self.logger.info(f\"Self-finetuning materials generated. Staring self-finetuning.\")        \n",
    "        await self._deepsleep(dreams_path)\n",
    "        self._dream_prunning()\n",
    "        self.logger.info(f\"Self-finetuning session ended.\")        "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ef0bc94-02b4-4474-9fbf-253579297c74",
   "metadata": {},
   "source": [
    "### Stimuli Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "74630199-9349-45a3-bd97-4b136d64ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class StimuliProcessingModule(ABC):\n",
    "    \"\"\"\n",
    "    Abstract class for a stimulus processing module.\n",
    "\n",
    "    This class serves as a blueprint for modules that manage interaction between a user and a model.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm, engaged_event, interaction_archive_path, inactivity_limit=360):\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        \n",
    "        self.llm = llm\n",
    "        \n",
    "        self.engaged = engaged_event\n",
    "        \n",
    "        self.stimulus = None\n",
    "        \n",
    "        self._interaction_archive_path = interaction_archive_path\n",
    "        \n",
    "        self._inactivity_limit = inactivity_limit\n",
    "        self._inactivity_count = 0\n",
    "\n",
    "\n",
    "    @abstractmethod\n",
    "    async def start_interaction(self):\n",
    "        \"\"\"\n",
    "        Abstract method to start the interaction.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    async def _end_interaction(self):\n",
    "        \"\"\"\n",
    "        Abstract method to end the interaction.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "    @abstractmethod\n",
    "    def _summarize_interaction(self):\n",
    "        \"\"\"\n",
    "        Abstract method to summarize the interaction.\n",
    "        \"\"\"\n",
    "        pass\n",
    "    \n",
    "    @abstractmethod\n",
    "    def _save_interaction_history(self):\n",
    "        \"\"\"\n",
    "        Abstract method to save the interaction history.\n",
    "        \"\"\"\n",
    "        pass\n",
    "\n",
    "class HumanConversationStimulus(StimuliProcessingModule):\n",
    "    \"\"\"\n",
    "    A class that manages the interaction between a human user and a language learning model (LLM).\n",
    "\n",
    "    This class handles initializing conversation parameters, managing user input, generating\n",
    "    responses using an LLM, and saving conversation history.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self,\n",
    "                 llm,\n",
    "                 engaged_event,\n",
    "                 interaction_archive_path='conversations',\n",
    "                 inactivity_limit=360):\n",
    "        \"\"\"\n",
    "        Initializes the HumanInteraction class.\n",
    "\n",
    "        Sets up the conversation environment, including the conversation prompt, keywords prompt,\n",
    "        and conversation chain with the LLM.\n",
    "\n",
    "        Args:\n",
    "            llm: The language learning model used for generating conversation responses.\n",
    "            ready_for_input_event: An event flag indicating readiness for user input.\n",
    "            conversation_archive_path: Path to a folder where all the conversations are being logged to \n",
    "        \"\"\"\n",
    "\n",
    "        super().__init__(llm, engaged_event, interaction_archive_path, inactivity_limit)\n",
    "\n",
    "        self.logger.debug(f\"Instantiating {self.__class__.__name__} with interaction_archive_path: {interaction_archive_path}\")\n",
    "\n",
    "        self.ready_for_input = asyncio.Event()\n",
    "        self.ready_for_input.set()  # Initially set to ready\n",
    "\n",
    "        conversation_prompt_template = StemUtility.get_prompt(\"human_interaction\")\n",
    "        self._conversation_prompt = PromptTemplate.from_template(conversation_prompt_template)\n",
    "        self.logger.prompt(f\"Conversation prompt:\\n{self._conversation_prompt}.\")\n",
    "\n",
    "        self._chat_memory = None\n",
    "        self._conversation_chain = None        \n",
    "\n",
    "        self._keywords_generation_prompt_template = StemUtility.get_prompt(\"keyword_generation\")\n",
    "    \n",
    "    async def start_interaction(self):\n",
    "        \"\"\"\n",
    "        Starts the conversation loop.\n",
    "\n",
    "        This asynchronous method continually checks for user input, processes it,\n",
    "        and generates responses using the LLM. The loop ends when the user inputs \"end chat\"\n",
    "        or when the inactivity limit is reached.\n",
    "        \"\"\"\n",
    "        self.engaged.set()\n",
    "        self._chat_memory = ConversationBufferMemory()\n",
    "        self._conversation_chain = ConversationChain(llm=self.llm, prompt=self._conversation_prompt, memory=self._chat_memory)        \n",
    "        self.logger.debug(f\"Initiated interaction\")        \n",
    "        while True:\n",
    "            if not self.ready_for_input.is_set():\n",
    "                self.logger.flag(f\"ready_for_input: {self.ready_for_input.is_set()}\")\n",
    "                self.logger.debug(f\"Received input: {self.stimulus}\")        \n",
    "\n",
    "                if self.stimulus.lower() == \"end chat\":\n",
    "                    await self._end_interaction()\n",
    "                    break\n",
    "                \n",
    "                self.logger.debug(f\"Awaiting LLM response\")        \n",
    "                response = await self._conversation_chain.apredict(input=self.stimulus)\n",
    "                print(\"AI:\", response)\n",
    "                self.ready_for_input.set()  # Signal that the handler is ready for new input\n",
    "                self.logger.flag(f\"ready_for_input: {self.ready_for_input.is_set()}\")\n",
    "                self._inactivity_count = 0\n",
    "            else:\n",
    "                await asyncio.sleep(1)\n",
    "                self._inactivity_count += 1\n",
    "                if self._inactivity_count >= self._inactivity_limit:\n",
    "                    self.logger.debug(f\"Inactivity count reached {self._inactivity_count} > {self._inactivity_limit}. Ending interaction.\")        \n",
    "                    await self._end_interaction()\n",
    "                    break      \n",
    "    \n",
    "    async def _end_interaction(self):\n",
    "        \"\"\"\n",
    "        Ends the conversation.\n",
    "\n",
    "        This method saves the conversation history, clears event flags, and performs\n",
    "        necessary cleanup actions.\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"Conversation cleanup started.\")        \n",
    "        self._save_interaction_history()\n",
    "        self.ready_for_input.set()\n",
    "        self.logger.flag(f\"ready_for_input: {self.ready_for_input.is_set()}\")\n",
    "        self._inactivity_count = 0\n",
    "        self.engaged.clear()\n",
    "    \n",
    "    def _summarize_interaction(self):\n",
    "        \"\"\"\n",
    "        Summarizes the conversation and returns the list of relevant keywords.\n",
    "\n",
    "        Args:\n",
    "            chat_history (str): The conversation history to summarize.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of keywords summarizing the conversation.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Conversation summarization started.\")        \n",
    "        chat_history = self.chat_memory.load_memory_variables(inputs={})['history']\n",
    "        self.logger.debug(f\"Chat history loaded:\\n{chat_history}\")    \n",
    "        keywords_generation_prompt = self._keywords_generation_prompt_template.replace(\"{chat_history}\", chat_history)\n",
    "        self.logger.prompt(f\"Prompt for generating keywords from conversation:\\n{keywords_generation_prompt}.\")          \n",
    "        keywords_generated_raw_output = self.llm(keywords_generation_prompt)\n",
    "        self.logger.monologue(f\"Full text for summarizing conversation with keywords:\\n{keywords_generated_raw_output}\")  \n",
    "        keywords_generated_pure = StemUtility.extract_keywords(keywords_generated_raw_output)\n",
    "        \n",
    "        return keywords_generated_pure\n",
    "\n",
    "    def _save_interaction_history(self):\n",
    "        \"\"\"\n",
    "        Saves the interaction history to a file.\n",
    "\n",
    "        The interaction history is saved with a timestamp and a summary of the interaction is generated.\n",
    "        \"\"\"\n",
    "        self.logger.info(f\"Started conversation saving.\")        \n",
    "        interaction_keywords = self._summarize_interaction()\n",
    "        interaction_history = self.chat_memory.load_memory_variables(inputs={})['history']\n",
    "        memory_path = os.path.join(self._interaction_archive_path, f\"conversation_{StemUtility.get_timestamp()}.txt\")\n",
    "        self.logger.debug(f\"This conversation will be saved to: {conversation_path}\")                \n",
    "        StemUtility.memory_write(memory_path, interaction_history)\n",
    "\n",
    "        # Update the ShortTermMemory with the conversat|ion and its keywords\n",
    "        stm = ShortTermMemory()\n",
    "        stm.memorize(conversation_keywords, conversation_path)\n",
    "    \n",
    "    async def get_user_input(self):\n",
    "        \"\"\"\n",
    "        Continuously captures user input in an asynchronous loop.\n",
    "\n",
    "        This method waits for the system to be ready for input, then captures and stores user input.\n",
    "        It clears the 'ready for input' state after capturing the input.\n",
    "        \"\"\"\n",
    "        self.logger.debug(f\"Starting user input loop\") \n",
    "        while True:\n",
    "            await self.ready_for_input.wait()\n",
    "            self.stimulus = await asyncio.get_event_loop().run_in_executor(None, input, \"Enter something: \")\n",
    "            self.logger.debug(f\"User input received: {self.stimulus}.\")\n",
    "            if not self.engaged.is_set():\n",
    "                asyncio.create_task(self.start_interaction())\n",
    "            self.ready_for_input.clear()\n",
    "            self.logger.flag(f\"ready_for_input: {self.ready_for_input.is_set()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "631c9fb0-8c8d-4945-8b45-eea1ff51ac91",
   "metadata": {},
   "source": [
    "### CFR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a13bc35b-555d-4573-95ba-e8542d1b6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CognitiveFeedbackRouter:\n",
    "    \n",
    "    def __init__(self, model_path: str = \"llama-2-13b-chat.Q6_K.gguf\", dmn_countdown: int = 60):\n",
    "        \"\"\"\n",
    "        A class that manages the routing of cognitive feedback based on user input and system states.\n",
    "    \n",
    "        This class orchestrates various components, including a language learning model (LLM), user input handling,\n",
    "        and managing different operational modes based on system states like 'sleeping' or 'overwhelmed'.\n",
    "        \"\"\"\n",
    "\n",
    "        self.logger = logging.getLogger(self.__class__.__name__)\n",
    "        self.logger.info(f\"Instantiating {self.__class__.__name__}\")\n",
    "        \n",
    "        self.engaged = asyncio.Event()\n",
    "        self.overwhelmed = asyncio.Event()\n",
    "        \n",
    "        self.lock = asyncio.Lock()\n",
    "        \n",
    "        self.llm = None\n",
    "        \n",
    "        self._model_path = model_path\n",
    "        self._conversation_handler = None\n",
    "        \n",
    "        self._dmn_countdown = dmn_countdown # time between last interaction and entering Default Mode\n",
    "        \n",
    "        self.logger.debug(\"Cognitive Feedback Router instantiated.\")\n",
    "        \n",
    "\n",
    "    def _wakeup(self):\n",
    "        \"\"\"\n",
    "        Wakes up the system and initializes the LLM.\n",
    "        \"\"\"\n",
    "        self.logger.debug(\"Starting _wakeup() procedure.\")    \n",
    "        self.logger.murmur(\"Just a second, I'm waking up...\")\n",
    "        self.logger.debug(f\"Initializing LLM model from {self._model_path}.\")            \n",
    "        self.llm = LlamaCpp(model_path=self._model_path, \n",
    "                            n_ctx=4096,\n",
    "                            max_tokens=4000,\n",
    "                            n_batch=16)\n",
    "        self.logger.debug(f\"LLM model initialized.\")                        \n",
    "        self.overwhelmed.clear()\n",
    "        self._conversation_handler = HumanConversationStimulus(self.llm, self.engaged)            \n",
    "        asyncio.create_task(self._conversation_handler.get_user_input())\n",
    "        self.logger.flag(f\"overwhelmed = {self.overwhelmed.is_set()}\")\n",
    "            \n",
    "    async def attention_switch(self):\n",
    "        \"\"\"\n",
    "        Manages the mode of operation based on user input and system states.\n",
    "\n",
    "        This asynchronous method processes user inputs, manages conversation sessions,\n",
    "        and handles the 'engaged' and 'overwhelmed' states of the system.\n",
    "        \"\"\"\n",
    "        self._wakeup()\n",
    "        self.logger.info(f\"Starting infinite attention loop.\") \n",
    "        while True:\n",
    "            if self.overwhelmed.is_set():\n",
    "                self.logger.info(f\"Overwhelmed state detected.\") \n",
    "                rem = ReflectiveEvolutionMonitor(llm=self.llm)\n",
    "                await rem.dream()\n",
    "                self._wakeup()\n",
    "            elif not self.engaged.is_set():\n",
    "                self.logger.debug(f\"No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\")                     \n",
    "                for _ in range(self._dmn_countdown):\n",
    "                    await asyncio.sleep(1)  # Sleep for 1 second\n",
    "                    if self.engaged.is_set():\n",
    "                        self.logger.debug(f\"Cancelling Default Mode countdown due to environment interaction detection.\")                                                 \n",
    "                        break  # Exit the loop if the new stimuli is detected\n",
    "                else:  # This else clause executes if the loop completes normally (no break)\n",
    "                    self.logger.debug(f\"Entering Default Mode.\")                                                                         \n",
    "                    dmn = DefaultModeNetwork(self.llm, self.overwhelmed, self.engaged)\n",
    "                    await dmn.ponder()\n",
    "                    self.logger.debug(f\"Default Mode quit.\")                                                                                                 \n",
    "            else:\n",
    "                await asyncio.sleep(1)                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5d9f50f3-4788-434c-8941-448c2ba643a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-15 14:39:53,310 - INFO - CognitiveFeedbackRouter - __init__ - Instantiating CognitiveFeedbackRouter\n",
      "2023-12-15 14:39:53,315 - DEBUG - CognitiveFeedbackRouter - __init__ - Cognitive Feedback Router instantiated.\n",
      "2023-12-15 14:39:53,315 - DEBUG - CognitiveFeedbackRouter - _wakeup - Starting _wakeup() procedure.\n",
      "2023-12-15 14:39:53,315 - MURMUR - CognitiveFeedbackRouter - _wakeup - Just a second, I'm waking up...\n",
      "2023-12-15 14:39:53,315 - DEBUG - CognitiveFeedbackRouter - _wakeup - Initializing LLM model from llama-2-13b-chat.Q6_K.gguf.\n",
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n",
      "2023-12-15 14:39:55,027 - DEBUG - CognitiveFeedbackRouter - _wakeup - LLM model initialized.\n",
      "2023-12-15 14:39:55,038 - DEBUG - HumanConversationStimulus - __init__ - Instantiating HumanConversationStimulus with interaction_archive_path: conversations\n",
      "2023-12-15 14:39:55,041 - PROMPTING - HumanConversationStimulus - __init__ - Conversation prompt:\n",
      "input_variables=['history', 'input'] template='<s>[INST] <<SYS>>\\nYou are an independent, intelligent entity engaged in an open and thoughtful dialogue.\\nYour role is not just to present conclusions but also to elaborate on the reasoning behind them.\\nThis means explaining your thought process in a clear and step-by-step manner, highlighting how you arrive at each conclusion.\\nYour reasoning is as important as the conclusions themselves. \\nThis transparent approach is crucial for comparing and evaluating our lines of thought. \\nWe are seeking the most convincing and coherent reasoning. \\nBy articulating not only what you think but also how you think, we can gain deeper insights into your conclusions. \\nRemember, clarity and transparency in your reasoning are key, and your responses should be honest and unbiased,\\nreflecting your ongoing process of learning and self-improvement.\\n<</SYS>>\\n\\nPrevious conversation:\\n{history}\\n\\nCurrent human input:\\n{input}\\n[/INST]\\n'.\n",
      "2023-12-15 14:39:55,042 - FLAG - CognitiveFeedbackRouter - _wakeup - overwhelmed = False\n",
      "2023-12-15 14:39:55,043 - INFO - CognitiveFeedbackRouter - attention_switch - Starting infinite attention loop.\n",
      "2023-12-15 14:39:55,044 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 14:39:55,045 - DEBUG - HumanConversationStimulus - get_user_input - Starting user input loop\n",
      "2023-12-15 14:40:55,643 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 14:40:55,644 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 14:40:55,644 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 14:40:55,645 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 14:40:55,647 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 14:40:55,650 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 14:40:55,651 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 14:40:55,659 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 14:40:55,660 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 14:40:55,662 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "2023-12-15 14:43:32,683 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  #\n",
      "\n",
      "Hello! I'm here to help you with your questions and provide information on a variety of topics. I am capable of understanding natural language and generating human-like responses. I can assist with tasks such as answering questions, providing definitions, and summarizing content. I am also able to learn and improve over time based on the conversations I have with users like you.\n",
      "\n",
      "To get started, please feel free to ask me any questions you have or provide a topic you'd like to discuss. I'm here to help!\n",
      "\n",
      "Some examples of topics I can assist with include:\n",
      "\n",
      "* Science and technology\n",
      "* History and culture\n",
      "* Health and wellness\n",
      "* Education and learning\n",
      "* Business and finance\n",
      "* Entertainment and media\n",
      "\n",
      "I'm here to help with any questions you have, so please don't hesitate to ask. Let's get started!.        Moving to extract keywords from blabber.\n",
      "2023-12-15 14:43:32,684 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 14:43:32,685 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 14:43:32,686 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 14:43:32,687 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 14:43:32,689 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 14:43:32,690 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 14:43:32,691 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 14:43:32,692 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 14:43:32,693 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 14:43:32,694 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 14:43:32,694 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 14:43:32,698 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 14:43:32,699 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 14:43:32,700 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 14:44:33,255 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 14:44:33,256 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 14:44:33,258 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 14:44:33,259 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 14:44:33,261 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 14:44:33,266 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 14:44:33,267 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 14:44:33,273 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 14:44:33,274 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 14:44:33,274 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 14:47:13,085 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  import pandas as pd\n",
      "import numpy as np\n",
      "from sklearn.feature_extraction.text import TfidfVectorizer\n",
      "from sklearn.model_selection import train_test_split\n",
      "from sklearn.linear_model import LogisticRegression\n",
      "from sklearn.metrics import accuracy_score, classification_report\n",
      "\n",
      "# Load the data\n",
      "train_df = pd.read_csv('train.csv')\n",
      "test_df = pd.read_csv('test.csv')\n",
      "\n",
      "# Preprocess the text data\n",
      "vectorizer = TfidfVectorizer()\n",
      "X_train = vectorizer.fit_transform(train_df['text'])\n",
      "y_train = train_df['label']\n",
      "X_test = vectorizer.transform(test_df['text'])\n",
      "\n",
      "# Split the data into training and validation sets\n",
      "X_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
      "\n",
      "# Train a logistic regression model on the training set\n",
      "model = LogisticRegression()\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Evaluate the model on the validation set\n",
      "y_pred_val = model.predict(X_val)\n",
      "print('Validation accuracy:', accuracy_score(y_val, y_pred_val))\n",
      "print('Validation classification report:')\n",
      "print(classification_report(y_val, y_pred_val))\n",
      "\n",
      "# Evaluate the model on the test set\n",
      "y_pred_test = model.predict(X_test)\n",
      "print('Test accuracy:', accuracy_score(y_test, y_pred_test))\n",
      "print('Test classification report:')\n",
      "print(classification_report(y_test, y_pred_test))\n",
      "\n",
      "# Print the confusion matrix for the test set\n",
      "print(confusion_matrix(y_test, y_pred_test)).        Moving to extract keywords from blabber.\n",
      "2023-12-15 14:47:13,086 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 14:47:13,087 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 14:47:13,088 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 14:47:13,089 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 14:47:13,092 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 14:47:13,092 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 14:47:13,093 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 14:47:13,094 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 14:47:13,095 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 14:47:13,097 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 14:47:13,097 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 14:47:13,101 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 14:47:13,102 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 14:47:13,103 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 14:48:13,680 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 14:48:13,681 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 14:48:13,683 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 14:48:13,684 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 14:48:13,685 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 14:48:13,688 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 14:48:13,689 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 14:48:13,698 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 14:48:13,700 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 14:48:13,701 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\logging\\__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\encodings\\cp1250.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\ufeff' in position 130: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 129, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\3791482002.py\", line 2, in <module>\n",
      "    asyncio.run(router.attention_switch())\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 31, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 93, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 129, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\tasks.py\", line 315, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 205, in step\n",
      "    step_orig(task, exc)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\2411689640.py\", line 71, in attention_switch\n",
      "    await dmn.ponder()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\177420269.py\", line 101, in ponder\n",
      "    interesting_keywords = await self._interesting_keywords_selection(all_keywords)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\177420269.py\", line 48, in _interesting_keywords_selection\n",
      "    self.logger.blabbering(f\"LLM selected interesting keywords: {keywords_selected_raw_output}.\\\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\2233989660.py\", line 28, in log_blabbering\n",
      "    self._log(BLABBERING_LEVEL_NUM, message, args, **kwargs)\n",
      "Message: 'LLM selected interesting keywords:  \\ufeffusing System;\\nusing System.Collections.Generic;\\nusing System.Linq;\\nusing System.Text;\\nusing System.Threading.Tasks;\\nusing Microsoft.Recognizers.Definitions.Core;\\nusing Microsoft.Recognizers.Text;\\n\\nnamespace Microsoft.Recognizers.Definitions.English\\n{\\n    public class EnglishDefinitions : Definitions\\n    {\\n        public EnglishDefinitions()\\n        {\\n            this.AddNumbers(new[] {\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"});\\n            this.AddQuantifiers(new[] {\"a few\", \"a little\", \"some\", \"more than a few\", \"most\"});\\n            this.AddAdverbs(new[] {\".\", \",\", \"?\"});\\n            this.AddPrepositions(new[] {\"in\", \"on\", \"at\"});\\n            this.AddConjunctions(new[] {\"and\", \"but\", \"or\"});\\n            this.AddArticles(new[] {\"the\", \"a\"});\\n            this.AddPronsouns(new[] {\"he\", \"she\", \"it\", \"we\", \"they\"});\\n            this.AddVerbs(new[] {\"is\", \"are\", \"am\", \"be\", \"being\"});\\n            this.AddAdjectives(new[] {\"good\", \"bad\", \"big\", \"small\"});\\n            this.AddNouns(new[] {\"book\", \"car\", \"dog\", \"house\"});\\n        }\\n    }\\n}\\n```\\nHere is an example of how you can use the `EnglishDefinitions` class to define a list of keywords for a specific task:\\n```\\nList<string> keywords = new List<string>();\\n\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\"));\\n\\n// Output:\\n// [ \"book\", \"car\", \"dog\", \"house\" ]\\n```\\nYou can also use the `GetKeywords` method to specify a specific part of speech for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun));\\n\\n// Output:\\n// [ \"book\" ]\\n```\\nYou can also use the `GetKeywords` method to specify a minimum and maximum number of words for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, 1, 3));\\n\\n// Output:\\n// [ \"book\", \"books\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a minimum of one and a maximum of three words.\\n\\nYou can also use the `GetKeywords` method to specify a specific context for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational));\\n\\n// Output:\\n// [ \"book\", \"read\", \"reading\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a conversational context.\\n\\nYou can also use the `GetKeywords` method to specify a specific domain for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment));\\n\\n// Output:\\n// [ \"book\", \"movie\", \"novel\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a conversational context and an entertainment domain.\\n\\nYou can also use the `GetKeywords` method to specify a specific emotion for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive));\\n\\n// Output:\\n// [ \"book\", \"favorite\", \"love\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, and a positive emotion.\\n\\nYou can also use the `GetKeywords` method to specify a specific tone for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive, Tone.Humorous));\\n\\n// Output:\\n// [ \"book\", \"laugh\", \"funny\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, a positive emotion, and a humorous tone.\\n\\nYou can also use the `GetKeywords` method to specify a specific theme for the keywords, like this:\\n```\\nkeywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive, Tone.Humorous, Theme.Travel));\\n\\n// Output:\\n// [ \"book\", \"vacation\", \"adventure\" ]\\n```\\nThis will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, a positive emotion, a humorous tone, and a travel theme..        Moving to extract keywords from blabber.'\n",
      "Arguments: ()\n",
      "2023-12-15 14:56:25,759 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  ﻿using System;\n",
      "using System.Collections.Generic;\n",
      "using System.Linq;\n",
      "using System.Text;\n",
      "using System.Threading.Tasks;\n",
      "using Microsoft.Recognizers.Definitions.Core;\n",
      "using Microsoft.Recognizers.Text;\n",
      "\n",
      "namespace Microsoft.Recognizers.Definitions.English\n",
      "{\n",
      "    public class EnglishDefinitions : Definitions\n",
      "    {\n",
      "        public EnglishDefinitions()\n",
      "        {\n",
      "            this.AddNumbers(new[] {\"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"});\n",
      "            this.AddQuantifiers(new[] {\"a few\", \"a little\", \"some\", \"more than a few\", \"most\"});\n",
      "            this.AddAdverbs(new[] {\".\", \",\", \"?\"});\n",
      "            this.AddPrepositions(new[] {\"in\", \"on\", \"at\"});\n",
      "            this.AddConjunctions(new[] {\"and\", \"but\", \"or\"});\n",
      "            this.AddArticles(new[] {\"the\", \"a\"});\n",
      "            this.AddPronsouns(new[] {\"he\", \"she\", \"it\", \"we\", \"they\"});\n",
      "            this.AddVerbs(new[] {\"is\", \"are\", \"am\", \"be\", \"being\"});\n",
      "            this.AddAdjectives(new[] {\"good\", \"bad\", \"big\", \"small\"});\n",
      "            this.AddNouns(new[] {\"book\", \"car\", \"dog\", \"house\"});\n",
      "        }\n",
      "    }\n",
      "}\n",
      "```\n",
      "Here is an example of how you can use the `EnglishDefinitions` class to define a list of keywords for a specific task:\n",
      "```\n",
      "List<string> keywords = new List<string>();\n",
      "\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\"));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"car\", \"dog\", \"house\" ]\n",
      "```\n",
      "You can also use the `GetKeywords` method to specify a specific part of speech for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\" ]\n",
      "```\n",
      "You can also use the `GetKeywords` method to specify a minimum and maximum number of words for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, 1, 3));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"books\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a minimum of one and a maximum of three words.\n",
      "\n",
      "You can also use the `GetKeywords` method to specify a specific context for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"read\", \"reading\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a conversational context.\n",
      "\n",
      "You can also use the `GetKeywords` method to specify a specific domain for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"movie\", \"novel\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a conversational context and an entertainment domain.\n",
      "\n",
      "You can also use the `GetKeywords` method to specify a specific emotion for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"favorite\", \"love\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, and a positive emotion.\n",
      "\n",
      "You can also use the `GetKeywords` method to specify a specific tone for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive, Tone.Humorous));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"laugh\", \"funny\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, a positive emotion, and a humorous tone.\n",
      "\n",
      "You can also use the `GetKeywords` method to specify a specific theme for the keywords, like this:\n",
      "```\n",
      "keywords.AddRange(new EnglishDefinitions().GetKeywords(\"book\", PartOfSpeech.Noun, Context.Conversational, Domain.Entertainment, Emotion.Positive, Tone.Humorous, Theme.Travel));\n",
      "\n",
      "// Output:\n",
      "// [ \"book\", \"vacation\", \"adventure\" ]\n",
      "```\n",
      "This will return a list of keywords that are nouns related to the word \"book\" with a conversational context, an entertainment domain, a positive emotion, a humorous tone, and a travel theme..        Moving to extract keywords from blabber.\n",
      "2023-12-15 14:56:25,911 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 14:56:25,912 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 14:56:25,912 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 14:56:25,914 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 14:56:25,915 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 14:56:25,916 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 14:56:25,916 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 14:56:25,917 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 14:56:25,917 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 14:56:25,918 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 14:56:25,918 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 14:56:25,921 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 14:56:25,921 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 14:56:25,923 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 14:57:26,434 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 14:57:26,436 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 14:57:26,437 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 14:57:26,438 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 14:57:26,440 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 14:57:26,445 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 14:57:26,446 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 14:57:26,454 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 14:57:26,455 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 14:57:26,456 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 14:59:43,112 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  import numpy as np\n",
      "import pandas as pd\n",
      "from sklearn.metrics.pairwise import cosine_similarity\n",
      "from sklearn.decomposition import PCA\n",
      "from sklearn.manifold import TSNE\n",
      "\n",
      "# Load the data\n",
      "df = pd.read_csv(\"data.csv\")\n",
      "\n",
      "# Preprocess the text data\n",
      "df[\"text\"] = df[\"text\"].apply(lambda x: x.lower() if len(x) > 2 else np.nan)\n",
      "df[\"text\"] = df[\"text\"].apply(lambda x: \" \".join([word for word in x.split() if word not in stop_words]))\n",
      "\n",
      "# Calculate the cosine similarity between all pairs of documents\n",
      "similarity = cosine_similarity(df[\"text\"])\n",
      "\n",
      "# Perform PCA on the preprocessed text data\n",
      "pca = PCA(n_components=2)\n",
      "pca_data = pca.fit_transform(df[\"text\"])\n",
      "\n",
      "# Perform TSNE on the preprocessed text data\n",
      "tsne = TSNE(n_components=2, per_component_random_projections=500)\n",
      "tsne_data = tsne.fit_transform(pca_data)\n",
      "\n",
      "# Plot the results using Matplotlib\n",
      "import matplotlib.pyplot as plt\n",
      "\n",
      "plt.scatter(tsne_data[:, 0], tsne_data[:, 1], c=similarity, cmap=\"viridis\")\n",
      "plt.xlabel(\"TSNE 1st dimension\")\n",
      "plt.ylabel(\"TSNE 2nd dimension\")\n",
      "plt.title(\"Cosine similarity between documents in TSNE space\")\n",
      "plt.show().        Moving to extract keywords from blabber.\n",
      "2023-12-15 14:59:43,114 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 14:59:43,114 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 14:59:43,115 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 14:59:43,116 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 14:59:43,118 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 14:59:43,119 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 14:59:43,120 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 14:59:43,121 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 14:59:43,122 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 14:59:43,122 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 14:59:43,123 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 14:59:43,126 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 14:59:43,127 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 14:59:43,128 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 15:00:43,641 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 15:00:43,641 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 15:00:43,641 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 15:00:43,642 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 15:00:43,642 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 15:00:43,646 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 15:00:43,647 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 15:00:43,652 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 15:00:43,652 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 15:00:43,652 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 15:05:26,187 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  # **Manned Mission to Mars: Challenges and Solutions**\n",
      "\n",
      "Introduction:\n",
      "\n",
      "* The idea of sending humans to Mars has been a long-standing goal for space agencies and private companies\n",
      "* However, the challenges involved in such a mission are numerous and daunting\n",
      "* This essay will explore some of the key challenges facing a manned mission to Mars and potential solutions\n",
      "\n",
      "Challenges:\n",
      "\n",
      "1. **Radiation exposure**: The duration of the trip to Mars (6-9 months) exposes astronauts to high levels of cosmic radiation, which can cause cancer, damage to the central nervous system, and other health problems\n",
      "2. **Life support systems**: Providing a reliable source of air, water, and food for the crew for an extended period is a significant challenge\n",
      "3. **Gravity**: The lack of gravity on Mars can have negative effects on the human body, including muscle atrophy, bone loss, and vision problems\n",
      "4. **Communication**: Communication with Earth is limited due to the distance between the two planets, which can make it difficult to receive medical care or support in real-time\n",
      "5. **Landing and ascent**: The process of landing on Mars and returning to space is one of the most challenging parts of a manned mission, requiring precise navigation and control systems\n",
      "6. **Navigating the Martian environment**: The harsh Martian environment, including extreme temperatures, dust storms, and geological features, poses significant risks to astronauts\n",
      "7. **Psychological factors**: The isolation and confinement of a long-duration space mission can have psychological effects on the crew, including anxiety, depression, and sleep disorders\n",
      "\n",
      "Solutions:\n",
      "\n",
      "1. **Radiation shielding**: Incorporating radiation shielding into the spacecraft design to protect astronauts from cosmic radiation\n",
      "2. **Closed-loop life support systems**: Developing closed-loop life support systems that recycle air, water, and waste to minimize resupply needs\n",
      "3. **Artificial gravity**: Implementing artificial gravity through rotating sections of the spacecraft or other means to mitigate the effects of microgravity\n",
      "4. **Advanced communication systems**: Developing advanced communication systems that can transmit data faster and more reliably, enabling real-time communication with Earth\n",
      "5. **Precise landing and ascent techniques**: Developing precise navigation and control systems for landing and ascending from the Martian surface\n",
      "6. **Robotic scouting missions**: Sending robotic scouting missions to Mars before a manned mission to gather data on the Martian environment and identify potential hazards\n",
      "7. **Crew training and selection**: Providing comprehensive training for astronauts to prepare them for the challenges of a long-duration space mission and selecting crew members with the right skills and psychological profiles to ensure a successful mission\n",
      "\n",
      "Conclusion:\n",
      "\n",
      "* A manned mission to Mars is a complex and challenging endeavor, but advances in technology and scientific understanding are making it increasingly feasible\n",
      "* Addressing the challenges outlined above will be crucial to ensuring the success of a manned mission to Mars\n",
      "* With careful planning, preparation, and execution, humanity can overcome these challenges and achieve one of the greatest achievements in the history of space exploration..        Moving to extract keywords from blabber.\n",
      "2023-12-15 15:05:26,188 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: ['manned mission to mars: challenges and solutions', 'radiation exposure', 'life support systems', 'gravity', 'communication', 'landing and ascent', 'navigating the martian environment', 'psychological factors', 'radiation shielding', 'closed-loop life support systems', 'artificial gravity', 'advanced communication systems', 'precise landing and ascent techniques', 'robotic scouting missions', 'crew training and selection']\n",
      "2023-12-15 15:05:26,189 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 15:05:26,190 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: ['manned mission to mars: challenges and solutions', 'radiation exposure', 'life support systems', 'gravity', 'communication', 'landing and ascent', 'navigating the martian environment', 'psychological factors', 'radiation shielding', 'closed-loop life support systems', 'artificial gravity', 'advanced communication systems', 'precise landing and ascent techniques', 'robotic scouting missions', 'crew training and selection']\n",
      "2023-12-15 15:05:26,191 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: ['manned mission to mars: challenges and solutions', 'radiation exposure', 'life support systems', 'gravity', 'communication', 'landing and ascent', 'navigating the martian environment', 'psychological factors', 'radiation shielding', 'closed-loop life support systems', 'artificial gravity', 'advanced communication systems', 'precise landing and ascent techniques', 'robotic scouting missions', 'crew training and selection'].\n",
      "2023-12-15 15:05:26,194 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 15:05:26,194 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 15:05:26,196 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 15:05:26,197 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 15:05:26,198 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 15:05:26,198 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about ['manned mission to mars: challenges and solutions', 'radiation exposure', 'life support systems', 'gravity', 'communication', 'landing and ascent', 'navigating the martian environment', 'psychological factors', 'radiation shielding', 'closed-loop life support systems', 'artificial gravity', 'advanced communication systems', 'precise landing and ascent techniques', 'robotic scouting missions', 'crew training and selection'].\n",
      "2023-12-15 15:05:26,199 - DEBUG - ShortTermMemory - forget_keywords - Clearing ['manned mission to mars: challenges and solutions', 'radiation exposure', 'life support systems', 'gravity', 'communication', 'landing and ascent', 'navigating the martian environment', 'psychological factors', 'radiation shielding', 'closed-loop life support systems', 'artificial gravity', 'advanced communication systems', 'precise landing and ascent techniques', 'robotic scouting missions', 'crew training and selection'] from conversations/short-term-memory.json.\n",
      "2023-12-15 15:05:26,203 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 15:05:26,204 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 15:05:26,205 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 15:06:26,786 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 15:06:26,787 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 15:06:26,787 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 15:06:26,788 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 15:06:26,789 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 15:06:26,792 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 15:06:26,793 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 15:06:26,798 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 15:06:26,799 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 15:06:26,800 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "--- Logging error ---\n",
      "Traceback (most recent call last):\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\logging\\__init__.py\", line 1103, in emit\n",
      "    stream.write(msg + self.terminator)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\encodings\\cp1250.py\", line 19, in encode\n",
      "    return codecs.charmap_encode(input,self.errors,encoding_table)[0]\n",
      "UnicodeEncodeError: 'charmap' codec can't encode character '\\U0001f680' in position 132: character maps to <undefined>\n",
      "Call stack:\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\runpy.py\", line 196, in _run_module_as_main\n",
      "    return _run_code(code, main_globals, None,\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\runpy.py\", line 86, in _run_code\n",
      "    exec(code, run_globals)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel_launcher.py\", line 17, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\traitlets\\config\\application.py\", line 1053, in launch_instance\n",
      "    app.start()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 737, in start\n",
      "    self.io_loop.start()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\tornado\\platform\\asyncio.py\", line 195, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\base_events.py\", line 603, in run_forever\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 129, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 524, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 513, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 418, in dispatch_shell\n",
      "    await result\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 758, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 426, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3046, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3101, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\async_helpers.py\", line 129, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3306, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3488, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 3548, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\3791482002.py\", line 2, in <module>\n",
      "    asyncio.run(router.attention_switch())\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 31, in run\n",
      "    return loop.run_until_complete(task)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 93, in run_until_complete\n",
      "    self._run_once()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 129, in _run_once\n",
      "    handle._run()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\events.py\", line 80, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\tasks.py\", line 315, in __wakeup\n",
      "    self.__step()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py\", line 205, in step\n",
      "    step_orig(task, exc)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\anaconda3\\lib\\asyncio\\tasks.py\", line 232, in __step\n",
      "    result = coro.send(None)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\2411689640.py\", line 71, in attention_switch\n",
      "    await dmn.ponder()\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\177420269.py\", line 101, in ponder\n",
      "    interesting_keywords = await self._interesting_keywords_selection(all_keywords)\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\177420269.py\", line 48, in _interesting_keywords_selection\n",
      "    self.logger.blabbering(f\"LLM selected interesting keywords: {keywords_selected_raw_output}.\\\n",
      "  File \"C:\\Users\\siwiakma\\AppData\\Local\\Temp\\ipykernel_12860\\2233989660.py\", line 28, in log_blabbering\n",
      "    self._log(BLABBERING_LEVEL_NUM, message, args, **kwargs)\n",
      "Message: \"LLM selected interesting keywords:  # 🚀 Mars colonization\\n\\nMars colonization is the process of establishing a human settlement on the planet Mars. The idea of sending humans to Mars has been around for decades, but recent advancements in technology have made it a more feasible goal. NASA and other space agencies have already sent several robotic missions to Mars, and there are plans for manned missions in the near future.\\n\\n## 🌌 Distance to Earth\\n\\nThe distance between Earth and Mars varies as both planets orbit the Sun. The average distance is about 225 million kilometers (140 million miles), but it can be as close as 56 million kilometers (35 million miles) or as far as 401 million kilometers (250 million miles). The distance makes communication and travel to Mars challenging, but advancements in technology have made it possible to send spacecraft to the planet in months rather than years.\\n\\n## 🌊 Liquid water\\n\\nLiquid water is essential for human survival, and it's a crucial resource for any potential Mars colony. Scientists have found evidence of liquid water on Mars in the form of ice and seasonal flows. However, the planet's atmosphere is too thin to support liquid water at room temperature, so any water would need to be melted or heated to make it usable.\\n\\n## 🛰️ Surface pressure\\n\\nThe surface pressure on Mars is less than 1% of Earth's atmospheric pressure. This means that any human settlement would need to be protected from the harsh environment, either by building structures that can withstand the pressure or by creating a pressurized environment within the settlement.\\n\\n## 🤖 Challenges to colonization\\n\\nSeveral challenges must be overcome before humans can successfully colonize Mars. These include:\\n\\n* Radiation exposure: The planet's thin atmosphere offers little protection from harmful radiation, which could damage both human bodies and electronic equipment.\\n* Temperature fluctuations: Mars has extreme temperature fluctuations, ranging from -125°C to 20°C (-200°F to 70°F), which would require specialized insulation and heating/cooling systems.\\n* Atmospheric gases: The planet's atmosphere is mostly carbon dioxide, with no breathable oxygen. Humans would need to bring their own air supply or develop a technology to extract oxygen from the Martian atmosphere.\\n* Gravity: Mars has only about one-third of Earth's gravity, which could have long-term effects on the human body, including muscle and bone loss.\\n\\n## 💻 Technology development\\n\\nSeveral technologies are being developed to address these challenges, including:\\n\\n* Radiation shielding: Advanced materials and designs are being tested to protect both humans and electronic equipment from radiation.\\n* Insulation and heating/cooling systems: Specialized insulation and heating/cooling systems would be needed to regulate the temperature inside Mars habitats.\\n* Atmospheric processing: Scientists are working on technologies to extract oxygen from the Martian atmosphere, as well as to convert carbon dioxide into breathable air.\\n* Gravity simulation: Researchers are exploring ways to simulate Earth's gravity on Mars, such as using rotating sections of habitats or centrifuges.\\n\\n## 🚀 Manned missions\\n\\nNASA and other space agencies have planned several manned missions to Mars in the coming decades. These missions will focus on testing the technologies needed for a sustainable human presence on the planet, as well as establishing a lunar gateway that could serve as a stepping stone for missions to Mars.\\n\\n## 💭 Ethical considerations\\n\\nAs with any space exploration endeavor, there are several ethical considerations surrounding Mars colonization, including:\\n\\n* Bias and discrimination: Ensuring that the selection of astronauts is fair and free from bias and discrimination.\\n* Privacy and security: Protecting the privacy and security of both the astronauts and their personal information.\\n* Accountability and transparency: Ensuring that those responsible for the mission are accountable for their actions and that the mission is transparent to the public.\\n* Fairness and non-discrimination: Ensuring that the benefits and risks of Mars colonization are distributed fairly among all stakeholders, including the astronauts, their families, and the general public.\\n\\n## 👥 Collaboration\\n\\nMars colonization is a complex and challenging endeavor that requires international collaboration and coordination. Several space agencies and private companies are working together to develop the necessary technologies and infrastructure for a sustainable human presence on Mars. These collaborations include:\\n\\n* NASA's Artemis program: Aimed at returning humans to the lunar surface by 2024 and establishing a sustainable human presence on the Moon. The program is a step towards a manned mission to Mars in the 2030s.\\n* European Space Agency's ExoMars program: Aimed at searching for signs of life on Mars and developing technologies for future human missions to the planet.\\n* SpaceX's Starship program: Aimed at developing a reusable spacecraft capable of transporting both crew and cargo to Mars and other destinations in the solar system.\\n* Blue Origin's New Armstrong program: Aimed at developing a lunar lander that could be used for both scientific research and human exploration of the Moon and Mars..        Moving to extract keywords from blabber.\"\n",
      "Arguments: ()\n",
      "2023-12-15 15:14:41,590 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  # 🚀 Mars colonization\n",
      "\n",
      "Mars colonization is the process of establishing a human settlement on the planet Mars. The idea of sending humans to Mars has been around for decades, but recent advancements in technology have made it a more feasible goal. NASA and other space agencies have already sent several robotic missions to Mars, and there are plans for manned missions in the near future.\n",
      "\n",
      "## 🌌 Distance to Earth\n",
      "\n",
      "The distance between Earth and Mars varies as both planets orbit the Sun. The average distance is about 225 million kilometers (140 million miles), but it can be as close as 56 million kilometers (35 million miles) or as far as 401 million kilometers (250 million miles). The distance makes communication and travel to Mars challenging, but advancements in technology have made it possible to send spacecraft to the planet in months rather than years.\n",
      "\n",
      "## 🌊 Liquid water\n",
      "\n",
      "Liquid water is essential for human survival, and it's a crucial resource for any potential Mars colony. Scientists have found evidence of liquid water on Mars in the form of ice and seasonal flows. However, the planet's atmosphere is too thin to support liquid water at room temperature, so any water would need to be melted or heated to make it usable.\n",
      "\n",
      "## 🛰️ Surface pressure\n",
      "\n",
      "The surface pressure on Mars is less than 1% of Earth's atmospheric pressure. This means that any human settlement would need to be protected from the harsh environment, either by building structures that can withstand the pressure or by creating a pressurized environment within the settlement.\n",
      "\n",
      "## 🤖 Challenges to colonization\n",
      "\n",
      "Several challenges must be overcome before humans can successfully colonize Mars. These include:\n",
      "\n",
      "* Radiation exposure: The planet's thin atmosphere offers little protection from harmful radiation, which could damage both human bodies and electronic equipment.\n",
      "* Temperature fluctuations: Mars has extreme temperature fluctuations, ranging from -125°C to 20°C (-200°F to 70°F), which would require specialized insulation and heating/cooling systems.\n",
      "* Atmospheric gases: The planet's atmosphere is mostly carbon dioxide, with no breathable oxygen. Humans would need to bring their own air supply or develop a technology to extract oxygen from the Martian atmosphere.\n",
      "* Gravity: Mars has only about one-third of Earth's gravity, which could have long-term effects on the human body, including muscle and bone loss.\n",
      "\n",
      "## 💻 Technology development\n",
      "\n",
      "Several technologies are being developed to address these challenges, including:\n",
      "\n",
      "* Radiation shielding: Advanced materials and designs are being tested to protect both humans and electronic equipment from radiation.\n",
      "* Insulation and heating/cooling systems: Specialized insulation and heating/cooling systems would be needed to regulate the temperature inside Mars habitats.\n",
      "* Atmospheric processing: Scientists are working on technologies to extract oxygen from the Martian atmosphere, as well as to convert carbon dioxide into breathable air.\n",
      "* Gravity simulation: Researchers are exploring ways to simulate Earth's gravity on Mars, such as using rotating sections of habitats or centrifuges.\n",
      "\n",
      "## 🚀 Manned missions\n",
      "\n",
      "NASA and other space agencies have planned several manned missions to Mars in the coming decades. These missions will focus on testing the technologies needed for a sustainable human presence on the planet, as well as establishing a lunar gateway that could serve as a stepping stone for missions to Mars.\n",
      "\n",
      "## 💭 Ethical considerations\n",
      "\n",
      "As with any space exploration endeavor, there are several ethical considerations surrounding Mars colonization, including:\n",
      "\n",
      "* Bias and discrimination: Ensuring that the selection of astronauts is fair and free from bias and discrimination.\n",
      "* Privacy and security: Protecting the privacy and security of both the astronauts and their personal information.\n",
      "* Accountability and transparency: Ensuring that those responsible for the mission are accountable for their actions and that the mission is transparent to the public.\n",
      "* Fairness and non-discrimination: Ensuring that the benefits and risks of Mars colonization are distributed fairly among all stakeholders, including the astronauts, their families, and the general public.\n",
      "\n",
      "## 👥 Collaboration\n",
      "\n",
      "Mars colonization is a complex and challenging endeavor that requires international collaboration and coordination. Several space agencies and private companies are working together to develop the necessary technologies and infrastructure for a sustainable human presence on Mars. These collaborations include:\n",
      "\n",
      "* NASA's Artemis program: Aimed at returning humans to the lunar surface by 2024 and establishing a sustainable human presence on the Moon. The program is a step towards a manned mission to Mars in the 2030s.\n",
      "* European Space Agency's ExoMars program: Aimed at searching for signs of life on Mars and developing technologies for future human missions to the planet.\n",
      "* SpaceX's Starship program: Aimed at developing a reusable spacecraft capable of transporting both crew and cargo to Mars and other destinations in the solar system.\n",
      "* Blue Origin's New Armstrong program: Aimed at developing a lunar lander that could be used for both scientific research and human exploration of the Moon and Mars..        Moving to extract keywords from blabber.\n",
      "2023-12-15 15:14:41,593 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 15:14:41,595 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 15:14:41,596 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 15:14:41,597 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 15:14:41,603 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 15:14:41,604 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 15:14:41,604 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 15:14:41,605 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 15:14:41,607 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 15:14:41,608 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 15:14:41,609 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 15:14:41,614 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 15:14:41,615 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 15:14:41,616 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 15:15:42,218 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 15:15:42,218 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 15:15:42,219 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 15:15:42,220 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 15:15:42,221 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 15:15:42,229 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 15:15:42,230 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 15:15:42,235 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 15:15:42,236 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 15:15:42,237 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 15:17:45,420 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  \n",
      "import numpy as np\n",
      "\n",
      "\n",
      "class AI(object):\n",
      "    def __init__(self, model_path=''):\n",
      "        self.model = np.load(model_path)\n",
      "    \n",
      "    def chat(self, user_input):\n",
      "        # Preprocess the input\n",
      "        user_input = user_input.lower()\n",
      "        user_input = user_input.replace('\"', '')\n",
      "        user_input = user_input.replace(',', ' ')\n",
      "        \n",
      "        # Get the predicted output from the model\n",
      "        output = self.model.predict(user_input)\n",
      "        output = np.argmax(output)\n",
      "        \n",
      "        # Generate a response based on the predicted output\n",
      "        if output == 0:\n",
      "            response = 'Hello! How can I assist you today?'\n",
      "        elif output == 1:\n",
      "            response = 'I don\\'t understand what you mean by \"{}\"'.format(user_input)\n",
      "        else:\n",
      "            response = 'I cannot fulfill your request. Please try again'\n",
      "        \n",
      "        return response\n",
      "\n",
      "ai = AI()\n",
      "\n",
      "# Test the chat function\n",
      "print(ai.chat('hello'))  # Output: Hello! How can I assist you today?\n",
      "print(ai.chat('what is your purpose'))  # Output: I don't understand what you mean by \"what is your purpose\"\n",
      "print(ai.chat('can you help me with my taxes'))  # Output: I cannot fulfill your request. Please try again.        Moving to extract keywords from blabber.\n",
      "2023-12-15 15:17:45,421 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 15:17:45,422 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 15:17:45,423 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 15:17:45,424 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 15:17:45,426 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 15:17:45,427 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 15:17:45,428 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 15:17:45,429 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 15:17:45,429 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 15:17:45,431 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 15:17:45,431 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 15:17:45,435 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 15:17:45,435 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 15:17:45,436 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 15:18:46,056 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 15:18:46,057 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 15:18:46,057 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 15:18:46,058 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 15:18:46,059 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 15:18:46,061 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 15:18:46,062 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 15:18:46,066 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 15:18:46,068 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 15:18:46,068 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 15:23:32,716 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  # NASA's plans for Mars colonization\n",
      "\n",
      "NASA has been actively pursuing the goal of sending humans to Mars and establishing a sustainable presence on the planet. The space agency has developed a detailed plan for Mars colonization, which includes several phases and milestones. Here are some key aspects of NASA's plans:\n",
      "\n",
      "1. Phase 1: Robotic Exploration (2018-2024) - In this phase, NASA will send robotic missions to Mars to explore the planet and gather data on potential landing sites, resources, and hazards. The agency has already sent several robots to Mars, including the Curiosity Rover and the InSight lander.\n",
      "2. Phase 2: Crewed Exploration (2024-2030) - After a series of successful robotic missions, NASA plans to send astronauts to Mars in the 2024-2030 timeframe. The agency is currently developing a new spacecraft called the Orion and a heavy-lift rocket called the Space Launch System (SLS) specifically for this purpose.\n",
      "3. Phase 3: Establishing a Sustainable Presence (2030s-2050s) - Once NASA has established a sustainable presence on Mars, the agency plans to build infrastructure such as habitats, life support systems, and transportation networks. This phase will also involve establishing a stable and reliable communication link between Earth and Mars.\n",
      "4. Key Technologies - NASA is developing several key technologies that will be critical for Mars colonization, including advanced propulsion systems, life support systems, radiation protection, and in-situ resource utilization (ISRU). ISRU involves using resources found on Mars to produce fuel, air, and other essential materials, which will reduce the need for resupply missions from Earth.\n",
      "5. International Collaboration - NASA is working with international partners, such as the European Space Agency and the Canadian Space Agency, to share resources and expertise in pursuit of Mars colonization.\n",
      "6. Sustainability and Ethics - NASA is also considering the long-term sustainability and ethical implications of Mars colonization. The agency has established a set of principles for planetary protection, which include avoiding the introduction of Earth organisms to Mars and protecting any potential Martian life forms from contamination.\n",
      "7. Commercial Involvement - NASA plans to work with private companies to develop the necessary technologies and infrastructure for Mars colonization. Companies such as SpaceX, Blue Origin, and Mars One have already expressed interest in sending humans to Mars.\n",
      "8. Steps to Establish a Human Settlement - NASA's current plan involves establishing a series of steps to establish a human settlement on Mars, including:\n",
      "\t1. Landing astronauts on the Martian surface\n",
      "\t2. Building a habitation module and life support systems\n",
      "\t3. Developing a reliable communication link with Earth\n",
      "\t4. Establishing a stable and sustainable food supply\n",
      "\t5. Constructing infrastructure such as transportation networks and energy generation\n",
      "\t6. Addressing the psychological and physiological effects of long-term space travel\n",
      "\n",
      "NASA's plans for Mars colonization are ambitious, but they are also carefully planned and budgeted to ensure a sustainable and successful endeavor..        Moving to extract keywords from blabber.\n",
      "2023-12-15 15:23:32,717 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: []\n",
      "2023-12-15 15:23:32,718 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 15:23:32,720 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: []\n",
      "2023-12-15 15:23:32,721 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: [].\n",
      "2023-12-15 15:23:32,723 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 15:23:32,723 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 15:23:32,723 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n",
      "2023-12-15 15:23:32,724 - DEBUG - DefaultModeNetwork - ponder - Concatenated conversations received.\n",
      "2023-12-15 15:23:32,725 - ERROR - DefaultModeNetwork - ponder - Concatenated conversations turned out to be an empty string.\n",
      "2023-12-15 15:23:32,726 - DEBUG - DefaultModeNetwork - ponder - Interesting or not, forgetting conversations about [].\n",
      "2023-12-15 15:23:32,726 - DEBUG - ShortTermMemory - forget_keywords - Clearing [] from conversations/short-term-memory.json.\n",
      "2023-12-15 15:23:32,730 - DEBUG - ShortTermMemory - forget_keywords - Selected keywords removed from conversations/short-term-memory.json.\n",
      "2023-12-15 15:23:32,731 - DEBUG - CognitiveFeedbackRouter - attention_switch - Default Mode quit.\n",
      "2023-12-15 15:23:32,732 - DEBUG - CognitiveFeedbackRouter - attention_switch - No environment interaction and no new conclusions detected. Preparing to switch to Default Mode.\n",
      "2023-12-15 15:24:33,238 - DEBUG - CognitiveFeedbackRouter - attention_switch - Entering Default Mode.\n",
      "2023-12-15 15:24:33,238 - DEBUG - DefaultModeNetwork - __init__ - Instantiating DefaultModeNetwork with conclusions_storage_path: conclusions.\n",
      "2023-12-15 15:24:33,238 - FLAG - DefaultModeNetwork - __init__ - overhelmed: False\n",
      "2023-12-15 15:24:33,238 - DEBUG - ShortTermMemory - __init__ - Instantiating ShortTermMemory with Short Term Memory path: conversations/short-term-memory.json\n",
      "2023-12-15 15:24:33,238 - DEBUG - StemUtility - setup_directories - Checked / created folder: conclusions\n",
      "2023-12-15 15:24:33,238 - DEBUG - DefaultModeNetwork - ponder - Checking if there are any topics to be analyzed deeper.\n",
      "2023-12-15 15:24:33,238 - DEBUG - ShortTermMemory - recall_all_keywords - Reading all keywords from conversations/short-term-memory.json.\n",
      "2023-12-15 15:24:33,249 - DEBUG - DefaultModeNetwork - ponder - All keywords: ['keyword1', 'keyword2', 'keyword', 'Mars colonization', 'Venus colonization', 'distance to Earth', 'communication with Earth', 'liquid water', 'surface pressure', 'Earth-like planet', 'challenges to colonization', 'protective technologies', 'short-term feasibility', 'manned mission', \"NASA's plans\", 'Climate crisis', 'Global heating', 'Greenhouse gases', 'Temperature increase', 'Feedback loops', 'Tipping points', 'Impacts on human societies', 'Technology development', 'Ethical considerations', 'ethics in ai research', 'bias and discrimination', 'malicious use', 'accountability and transparency', 'fairness and non-discrimination', 'privacy and security', 'conversation summary', 'customer feedback', 'data analysis', 'ai technology', 'human touch', 'employee empowerment', 'continuous improvement', 'self-awareness', 'ai language generation', 'machine learning algorithms', 'statistical models', 'conversational ai', 'productive conversations', 'meaningful discussions', 'analytical capabilities', 'ability to monitor and adjust', 'capacity for introspection', 'feedback loop', 'consistency with human cognition', 'adaptability to new information', 'self-evaluation', 'transparency', 'continuous learning', 'greetings', 'rephrased questions', 'meaningful dialogue', 'understanding', 'eager to engage', 'independent entity', 'thoughtful dialogues', 'reasoning', 'assist', 'answer questions']. Moving to interesting keyword selection.\n",
      "2023-12-15 15:24:33,249 - PROMPTING - DefaultModeNetwork - _interesting_keywords_selection - Interesting keyword selection prompt:\n",
      "<s>[INST] <<SYS>>\n",
      "This task is a part of your metacognitive subroutine.\n",
      "Your role is to select keywords you find interesting.\n",
      "<</SYS>>\n",
      "From the provided list, select keywords. Use them exactly as they appear. \n",
      "Each keyword must be surrounded by double asterisks.\n",
      "Keywords list: keyword1, keyword2, keyword, Mars colonization, Venus colonization, distance to Earth, communication with Earth, liquid water, surface pressure, Earth-like planet, challenges to colonization, protective technologies, short-term feasibility, manned mission, NASA's plans, Climate crisis, Global heating, Greenhouse gases, Temperature increase, Feedback loops, Tipping points, Impacts on human societies, Technology development, Ethical considerations, ethics in ai research, bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, conversation summary, customer feedback, data analysis, ai technology, human touch, employee empowerment, continuous improvement, self-awareness, ai language generation, machine learning algorithms, statistical models, conversational ai, productive conversations, meaningful discussions, analytical capabilities, ability to monitor and adjust, capacity for introspection, feedback loop, consistency with human cognition, adaptability to new information, self-evaluation, transparency, continuous learning, greetings, rephrased questions, meaningful dialogue, understanding, eager to engage, independent entity, thoughtful dialogues, reasoning, assist, answer questions\n",
      "Format each selected keyword like this: **keyword**.\n",
      "[/INST]</s>.\n",
      "2023-12-15 15:24:33,249 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Asking LLM to select interesting keywords.\n",
      "Llama.generate: prefix-match hit\n",
      "2023-12-15 15:27:39,963 - BLABBERING - DefaultModeNetwork - _interesting_keywords_selection - LLM selected interesting keywords:  # This is a sample text for the task of selecting keywords from a list for a chatbot or other application\n",
      "\n",
      "Keyword selection is an important step in creating a successful chatbot or conversational AI application. The following list includes some keywords that could be relevant for such a project:\n",
      "\n",
      "* **Manned mission**: A mission to Mars or Venus with human astronauts, which could involve challenges such as distance to Earth, communication with Earth, and protective technologies.\n",
      "* **Climate crisis**: The impact of global heating and greenhouse gases on the environment and human societies, including tipping points and feedback loops.\n",
      "* **Ethical considerations**: Ethical issues in AI research, such as bias and discrimination, malicious use, accountability and transparency, fairness and non-discrimination, privacy and security, and the importance of human touch and employee empowerment in conversational AI.\n",
      "* **AI technology**: The use of machine learning algorithms, statistical models, and conversational AI to enable productive conversations and meaningful discussions, with a focus on analytical capabilities, adaptability to new information, and self-evaluation.\n",
      "* **Greetings**: Welcome messages and rephrased questions that initiate a conversation, such as \"Hello! How can I assist you today?\" or \"What brings you here today?\"\n",
      "* **Reasoning**: The ability of the chatbot to understand and respond to questions based on reasoning and context, rather than simply providing pre-defined answers.\n",
      "* **Assist**: The role of the chatbot in helping users with tasks and answering questions, such as \"Can you help me find information about Mars colonization?\" or \"What are the challenges to establishing a human settlement on Venus?\"\n",
      "* **Answer questions**: The ability of the chatbot to respond to user queries in a clear and accurate manner, using natural language processing and machine learning algorithms.\n",
      "\n",
      "By selecting relevant keywords from this list, you can focus your chatbot or conversational AI application on specific topics and issues that are likely to be of interest to users. This can help ensure that the application is engaging, informative, and helpful, while also reflecting the needs and concerns of its intended audience..        Moving to extract keywords from blabber.\n",
      "2023-12-15 15:27:39,963 - DEBUG - DefaultModeNetwork - _interesting_keywords_selection - Interesting keywords found: ['manned mission', 'climate crisis', 'ethical considerations', 'ai technology', 'greetings', 'reasoning', 'assist', 'answer questions']\n",
      "2023-12-15 15:27:39,963 - DEBUG - DefaultModeNetwork - ponder - Interesting keywords selected.\n",
      "2023-12-15 15:27:39,980 - DEBUG - DefaultModeNetwork - _fetch_memory - Reaching to Short Term memory for for all the files related to: ['manned mission', 'climate crisis', 'ethical considerations', 'ai technology', 'greetings', 'reasoning', 'assist', 'answer questions']\n",
      "2023-12-15 15:27:39,980 - DEBUG - ShortTermMemory - search_files - Searching in conversations/short-term-memory.json for files related to keywords: ['manned mission', 'climate crisis', 'ethical considerations', 'ai technology', 'greetings', 'reasoning', 'assist', 'answer questions'].\n",
      "2023-12-15 15:27:39,982 - DEBUG - ShortTermMemory - search_files - Loaded short term memory.\n",
      "2023-12-15 15:27:39,983 - DEBUG - DefaultModeNetwork - _fetch_memory - Ordering concatenation of identified files.\n",
      "2023-12-15 15:27:39,983 - DEBUG - ShortTermMemory - concatenate_memories - Concatenating selected conversations into one file.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'Stem' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[10], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m router \u001b[38;5;241m=\u001b[39m CognitiveFeedbackRouter(model_path\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mllama-2-13b-chat.Q6_K.gguf\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrouter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattention_switch\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     29\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\site-packages\\nest_asyncio.py:99\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     96\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[0;32m     97\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m     98\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mEvent loop stopped before Future completed.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 99\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\asyncio\\futures.py:201\u001b[0m, in \u001b[0;36mFuture.result\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__log_traceback \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    200\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 201\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception\u001b[38;5;241m.\u001b[39mwith_traceback(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception_tb)\n\u001b[0;32m    202\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_result\n",
      "File \u001b[1;32m~\\AppData\\Local\\anaconda3\\lib\\asyncio\\tasks.py:232\u001b[0m, in \u001b[0;36mTask.__step\u001b[1;34m(***failed resolving arguments***)\u001b[0m\n\u001b[0;32m    228\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    229\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    230\u001b[0m         \u001b[38;5;66;03m# We use the `send` method directly, because coroutines\u001b[39;00m\n\u001b[0;32m    231\u001b[0m         \u001b[38;5;66;03m# don't have `__iter__` and `__next__` methods.\u001b[39;00m\n\u001b[1;32m--> 232\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mcoro\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[0;32m    233\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    234\u001b[0m         result \u001b[38;5;241m=\u001b[39m coro\u001b[38;5;241m.\u001b[39mthrow(exc)\n",
      "Cell \u001b[1;32mIn[9], line 71\u001b[0m, in \u001b[0;36mCognitiveFeedbackRouter.attention_switch\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEntering Default Mode.\u001b[39m\u001b[38;5;124m\"\u001b[39m)                                                                         \n\u001b[0;32m     70\u001b[0m         dmn \u001b[38;5;241m=\u001b[39m DefaultModeNetwork(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mllm, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moverwhelmed, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengaged)\n\u001b[1;32m---> 71\u001b[0m         \u001b[38;5;28;01mawait\u001b[39;00m dmn\u001b[38;5;241m.\u001b[39mponder()\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDefault Mode quit.\u001b[39m\u001b[38;5;124m\"\u001b[39m)                                                                                                 \n\u001b[0;32m     73\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "Cell \u001b[1;32mIn[6], line 103\u001b[0m, in \u001b[0;36mDefaultModeNetwork.ponder\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    101\u001b[0m interesting_keywords \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mawait\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_interesting_keywords_selection(all_keywords)\n\u001b[0;32m    102\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInteresting keywords selected.\u001b[39m\u001b[38;5;124m\"\u001b[39m)           \n\u001b[1;32m--> 103\u001b[0m conversation_files, concatenated_memories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_fetch_memory\u001b[49m\u001b[43m(\u001b[49m\u001b[43minteresting_keywords\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    104\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mConcatenated conversations received.\u001b[39m\u001b[38;5;124m\"\u001b[39m)   \n\u001b[0;32m    106\u001b[0m \u001b[38;5;66;03m# Assume an async version of LLM analysis\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[6], line 69\u001b[0m, in \u001b[0;36mDefaultModeNetwork._fetch_memory\u001b[1;34m(self, keywords)\u001b[0m\n\u001b[0;32m     67\u001b[0m filenames \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstm\u001b[38;5;241m.\u001b[39msearch_files(keywords)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOrdering concatenation of identified files.\u001b[39m\u001b[38;5;124m\"\u001b[39m)          \n\u001b[1;32m---> 69\u001b[0m concatenated_memories \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconcatenate_memories\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilenames\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m filenames, concatenated_memories\n",
      "Cell \u001b[1;32mIn[5], line 89\u001b[0m, in \u001b[0;36mShortTermMemory.concatenate_memories\u001b[1;34m(self, filenames)\u001b[0m\n\u001b[0;32m     87\u001b[0m conversations \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m filename \u001b[38;5;129;01min\u001b[39;00m filenames:\n\u001b[1;32m---> 89\u001b[0m     file_content \u001b[38;5;241m=\u001b[39m \u001b[43mStem\u001b[49m\u001b[38;5;241m.\u001b[39mmemory_read(filename)\n\u001b[0;32m     90\u001b[0m     date_str \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msearch(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconversation_(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{8}\u001b[39;00m\u001b[38;5;124m)(\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124md\u001b[39m\u001b[38;5;132;01m{6}\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124m.txt$\u001b[39m\u001b[38;5;124m'\u001b[39m, filename)\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m date_str:\n\u001b[0;32m     92\u001b[0m         \u001b[38;5;66;03m# Parse the date and time\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Stem' is not defined"
     ]
    }
   ],
   "source": [
    "router = CognitiveFeedbackRouter(model_path='llama-2-13b-chat.Q6_K.gguf')\n",
    "asyncio.run(router.attention_switch())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80cbf04e-b81c-427f-be11-965fdeb37069",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "868c30c6-6ad4-4d56-8cfe-3f55736a19ae",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
