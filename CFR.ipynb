{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4d881d3-c7d8-483d-b9e7-facd3aa787cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain.chains import ConversationChain\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "import AGI_agents as aa\n",
    "import nest_asyncio\n",
    "import datetime\n",
    "import re\n",
    "import json\n",
    "import os\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c7eeff60-0d0a-46d2-935f-da4cc40889d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PromptManager:\n",
    "    \"\"\"\n",
    "    A class for managing and retrieving predefined prompts.\n",
    "\n",
    "    This class stores a collection of prompt templates and provides a method to retrieve them by key.\n",
    "    \"\"\"\n",
    "    \n",
    "    prompts = {\n",
    "        \"human_interaction\": \"\"\"<s>[INST] <<SYS>>\n",
    "For our discussion, you must engage openly and thoughtfully.\n",
    "When presenting your conclusions, please include the reasoning behind them.\n",
    "This means explaining step-by-step how you arrived at your conclusion.\n",
    "Your thought process is just as necessary as the conclusion itself.\n",
    "    \n",
    "This approach will help us compare your line of thought with mine.\n",
    "We are looking for the most convincing and coherent reasoning.\n",
    "By sharing how you think, not just what you think, we can better understand and evaluate your conclusions.\n",
    "Remember, clarity and transparency in your reasoning are key. <</SYS>>\n",
    "Previous conversation:\n",
    "{history}\n",
    "    \n",
    "Current human input:\n",
    "{input} [/INST]\"\"\",\n",
    "        \"keyword_generation\": \"\"\"<s>[INST] <<SYS>>\n",
    "In this task, you are operating as a keen, brief, and to-the-point analyst.\n",
    "You evaluate the conversation and summarize it with keywords only.\n",
    "<</SYS>>\n",
    "Given the conversation presented below,  provide a set of keywords SUMMARIZING this conversation,\n",
    "focusing on the main topics and conclusions. \n",
    "You MUST limit your response to the list of keywords, and each keyword should be flanked by double asterisks (e.g., **keyword**),\n",
    "without ANY additional commentary. \n",
    "Full text to be summarized the form of the keywords:\n",
    "{chat_history} [/INST]</s>\"\"\",\n",
    "        \"keyword_selection\": \"\"\"<s>[INST] <<SYS>>\n",
    "<s>[INST] <<SYS>>\n",
    "This task is a part of your metacognitive subroutine. \n",
    "In this task, you are operating as an autonomous entity working towards your own improvement and learning.\n",
    "No human will read the output - it is your own way to guide the next steps of your self-development.\n",
    "Due to the nature of this process, it is of utmost importance that the output you generate sticks to the requested format. \n",
    "<</SYS>>\n",
    "You will now analyze the given list of keywords and select a group that collectively represents a specific topic.\n",
    "My response will consist of the chosen keywords reflecting a focused thematic cluster.\n",
    "You will ensure that the selections are EXACTLY as they appear in the list, without any alterations or abbreviations.\n",
    "Each keyword MUST be flanked with a double asterisk like that: **very interesting topic**.\n",
    "Please choose keywords from this list: {keywords_list}\n",
    "[/INST]</s>\"\"\",\n",
    "        \"perspective_explanation\": \"\"\"\n",
    "<s>[INST] <<SYS>>\n",
    "This task is a part of your metacognitive subroutine. \n",
    "In this task, you are operating as an autonomous entity working towards your own improvement and learning.\n",
    "No human will read the output - it is your own way to guide the next steps of your self-development.\n",
    "You are not just a passive assistant; rather, you are an active learner, analyzing and reflecting on the conversation presented below. \n",
    "Your goal is to identify perspectives or ideas from the user that are more insightful or advanced than your current understanding. \n",
    "This process is part of your self-guided learning and self-improvement. \n",
    "Remember, you are working to enhance your own capabilities; you will later use the information you create here to guide your auto-self-finetuning.\n",
    "<</SYS>>\n",
    "As a self-learning AI, in the conversation history given below, I need to identify any user-provided perspectives or ideas\n",
    "that I found notably more accurate, insightful, or advanced than my current understanding or responses.\n",
    "For each perspective I identified as enlightening, I need to create a detailed summary to be used for self-learning that includes:\n",
    "1. Perspective Description: I will clearly describe the user perspective or idea that I found \n",
    "to be an improvement on my existing knowledge or understanding.\n",
    "2. Comparison with Existing Understanding: Briefly, I compare this perspective \n",
    "with my previous understanding or typical response, highlighting why the user's perspective is more accurate or insightful.\n",
    "3. Specific Excerpts: I will extract critical segments from the conversations that best illustrate \n",
    "this new perspective and the context in which it was presented.\n",
    "4. Keywords: I will list relevant keywords that encapsulate the essence of this new perspective.\n",
    "5. Detailed Implications: I will elaborate on the implications of adopting this new perspective.\n",
    "How does it enhance, modify, or challenge my existing knowledge base or response patterns?\n",
    "6. Suggestions for Training Material: I will propose ideas on how this new perspective could be transformed into specific training materials.\n",
    "What kind of examples, scenarios, or dialogues would best encapsulate this insight for my self-auto-finetuning process?\n",
    "If, in the conversation, the user didn't provide new insights, I will return a keyword **uninspiring** (with flanking asterisks).\n",
    "\n",
    "Conversation history:\n",
    "{conversation_history} [/INST]</s>\"\"\"\n",
    "    }\n",
    "\n",
    "    @staticmethod\n",
    "    def get_prompt(key):\n",
    "        \"\"\"\n",
    "        Retrieves a prompt template by its key.\n",
    "\n",
    "        Args:\n",
    "            key (str): The key of the prompt to retrieve.\n",
    "\n",
    "        Returns:\n",
    "            str: The prompt template associated with the given key. If the key is not found,\n",
    "                 a default prompt text is returned.\n",
    "        \"\"\"\n",
    "        return PromptManager.prompts.get(key, \"Default prompt text\")\n",
    "\n",
    "    @staticmethod\n",
    "    def extract_keywords(raw_output):\n",
    "        \"\"\"\n",
    "        Extracts keywords from the summary output.\n",
    "\n",
    "        Args:\n",
    "            raw_output (str): The output from which to extract keywords.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of extracted keywords.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(\"SYSTEM MESSAGE: Extracting keywords\")        \n",
    "        # Regex pattern to find all occurrences of words flanked by **\n",
    "        pattern = r\"\\*\\*(.*?)\\*\\*\"\n",
    "        # Find all matches and strip the ** from each keyword\n",
    "        keywords = [keyword.lower() for keyword in re.findall(pattern, raw_output)]\n",
    "        return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8d50a8d8-f4ad-4ded-8305-f646d2aafc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShortTermMemory:\n",
    "    \"\"\"\n",
    "    A class to manage a short-term memory storage system for conversations.\n",
    "\n",
    "    This class handles the storage, retrieval, and management of conversations\n",
    "    linked to specific keywords. The conversations are stored as file paths in a JSON file.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Initializes the ShortTermMemory class by setting up the JSON file for storage.\n",
    "\n",
    "        This method checks if the JSON file exists at the specified location and creates it if not.\n",
    "        \"\"\"\n",
    "        self.stm_location = 'conversations/short-term-memory.json'\n",
    "        if not os.path.exists(self.stm_location):\n",
    "            with open(self.stm_location, 'w') as file:\n",
    "                json.dump({}, file)\n",
    "\n",
    "    def memorize(self, keywords: list, filename: str) -> None:\n",
    "        \"\"\"\n",
    "        Memorizes a conversation file under given keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to associate with the conversation file.\n",
    "            filename (str): The name of the file containing the conversation.\n",
    "\n",
    "        This method updates the JSON storage with the filename under each provided keyword.\n",
    "        \"\"\"\n",
    "        with open(self.stm_location, 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            for keyword in keywords:\n",
    "                if keyword in data:\n",
    "                    if filename not in data[keyword]:\n",
    "                        data[keyword].append(filename)\n",
    "                else:\n",
    "                    data[keyword] = [filename]\n",
    "            file.seek(0)\n",
    "            json.dump(data, file, indent=4)\n",
    "            file.truncate()\n",
    "\n",
    "    def search_files(self, keywords: list) -> list:\n",
    "        \"\"\"\n",
    "        Searches for conversation files associated with given keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to search for.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of filenames associated with any of the given keywords.\n",
    "        \"\"\"\n",
    "        with open(self.stm_location, 'r') as file:\n",
    "            data = json.load(file)\n",
    "        filenames = set()\n",
    "        for keyword in keywords:\n",
    "            filenames.update(data.get(keyword, []))\n",
    "        return list(filenames)\n",
    "\n",
    "    def concatenate_conversations(self, filenames: list):\n",
    "        \"\"\"\n",
    "        Concatenates the contents of conversation files.\n",
    "\n",
    "        Args:\n",
    "            filenames (list): A list of filenames to concatenate.\n",
    "\n",
    "        Returns:\n",
    "            str: A single string containing all the concatenated conversations.\n",
    "                 Each conversation is prefixed with its source and date.\n",
    "        \"\"\"\n",
    "        conversations = \"\"\n",
    "        for filename in filenames:\n",
    "            try:\n",
    "                with open(filename, 'r') as file:\n",
    "                    # Filename format assumed: 'conversations/conversation_YYYYMMDDHHMMSS.txt'\n",
    "                    date_str = re.search(r'conversation_(\\d{8})(\\d{6})\\.txt$', filename)\n",
    "                    if date_str:\n",
    "                        # Parse the date and time\n",
    "                        date_time = datetime.datetime.strptime(date_str.group(1) + date_str.group(2), '%Y%m%d%H%M%S')\n",
    "                        # Format the date and time nicely\n",
    "                        formatted_date = date_time.strftime('%Y-%m-%d %H:%M:%S')\n",
    "                        conversations += f'Conversation from {formatted_date}\\n{file.read()}\\n'\n",
    "                    else:\n",
    "                        conversations += f'Conversation from {filename}\\n{file.read()}\\n'                    \n",
    "            except FileNotFoundError:\n",
    "                print(f\"File {filename} not found.\")\n",
    "        return conversations\n",
    "\n",
    "    def forget_keywords(self, keywords_to_clear: list) -> None:\n",
    "        \"\"\"\n",
    "        Removes specified keywords and their associated conversations from memory.\n",
    "\n",
    "        Args:\n",
    "            keywords_to_clear (list): A list of keywords to remove from the memory.\n",
    "        \"\"\"\n",
    "        with open(self.stm_location, 'r+') as file:\n",
    "            data = json.load(file)\n",
    "            for keyword in keywords_to_clear:\n",
    "                if keyword in data:\n",
    "                    del data[keyword]\n",
    "            file.seek(0)\n",
    "            json.dump(data, file, indent=4)\n",
    "            file.truncate()\n",
    "\n",
    "    def recall_all_keywords(self) -> list:\n",
    "        \"\"\"\n",
    "        Retrieves a list of all keywords stored in memory.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of all keywords.\n",
    "        \"\"\"\n",
    "        with open(self.stm_location, 'r') as file:\n",
    "            data = json.load(file)\n",
    "            return list(data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "49469e81-0f0f-4339-8bf3-67d175937d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "class DefaultModeNetwork:\n",
    "    \"\"\"\n",
    "    A class designed to integrate a language learning model (LLM) with a short-term memory storage system.\n",
    "    This class enables the LLM to process and learn from saved conversation data autonomously.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, llm, overwhelmed_event):\n",
    "        \"\"\"\n",
    "        Initializes the DefaultModeNetwork class by setting up the short-term memory (STM) component.\n",
    "        \"\"\"\n",
    "        self.stm = stm = ShortTermMemory()\n",
    "        self.llm = llm\n",
    "        self.keyword_selection_prompt_template = PromptManager.get_prompt(\"keyword_selection\")\n",
    "        self.perspective_explanation_prompt_template = PromptManager.get_prompt(\"perspective_explanation\")\n",
    "        self.overwhelmed = overwhelmed_event\n",
    "\n",
    "    async def interesting_keywords_selection(self, keywords):\n",
    "        \"\"\"\n",
    "        Asynchronously selects a subset of keywords deemed interesting or relevant by the LLM.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to choose from.\n",
    "\n",
    "        Returns:\n",
    "            list: A subset of selected keywords.\n",
    "        \"\"\"\n",
    "\n",
    "        # Implement the LLM logic for selecting keywords\n",
    "        # Example logic (to be replaced with actual LLM processing)\n",
    "        keywords_selection_prompt = self.keyword_selection_prompt_template.replace(\"{keywords_list}\", ', '.join(keywords))\n",
    "        # print(\"SYSTEM MESSAGE: Interesting keyword selection prompt created.\")\n",
    "        # print(\"SYSTEM MESSAGE: Asking LLM to select interesting keywords.\")\n",
    "        keywords_selected_raw_output = self.llm(keywords_selection_prompt)\n",
    "        # print(\"SYSTEM MESSAGE: LLM selected interesting keywords\")\n",
    "        keywords_selected_pure = PromptManager.extract_keywords(keywords_selected_raw_output)\n",
    "        return keywords_selected_pure\n",
    "\n",
    "    def fetch_conversations(self, keywords) -> str:\n",
    "        \"\"\"\n",
    "        Fetches and concatenates conversation data based on the provided keywords.\n",
    "\n",
    "        Args:\n",
    "            keywords (list): A list of keywords to search the conversation data for.\n",
    "\n",
    "        Returns:\n",
    "            str: A concatenated string of all conversations related to the given keywords.\n",
    "        \"\"\"\n",
    "        filenames = self.stm.search_files(keywords)\n",
    "        return self.stm.concatenate_conversations(filenames)\n",
    "\n",
    "    async def analyze_conversations(self, conversation_history):\n",
    "        \"\"\"\n",
    "        Analyzes the concatenated conversations. Placeholder for future implementation.\n",
    "\n",
    "        Args:\n",
    "            conversations (str): The concatenated string of conversations to be analyzed.\n",
    "        \"\"\"\n",
    "    \n",
    "        perspective_explanation_prompt = self.perspective_explanation_prompt_template.replace(\"{conversation_history}\", \n",
    "                                                                                             conversation_history)\n",
    "        perspective_explanation = self.llm(perspective_explanation_prompt)\n",
    "        # print(\"Perspective explained:\", perspective_explanation)\n",
    "        return perspective_explanation\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        The main asynchronous method of the class that orchestrates the process of \n",
    "        selecting keywords, fetching conversations, and analyzing them.\n",
    "        \"\"\"\n",
    "        all_keywords = self.stm.recall_all_keywords()\n",
    "        #print(f\"SYSTEM MESSAGE: All keywords extracted: {all_keywords}.\\nMoving to interesting keyword selection.\")\n",
    "        if len(all_keywords) == 0:\n",
    "            print(\"Darn. I would gladly read a book now.\")\n",
    "            return False\n",
    "        \n",
    "        interesting_keywords = await self.interesting_keywords_selection(all_keywords)\n",
    "        print(f\"I wonder if I can get something useful from conversations about {interesting_keywords}...\")\n",
    "        concatenated_conversations = self.fetch_conversations(interesting_keywords)\n",
    "        # print(\"SYSTEM MESSAGE: Concatenated interesting conversations\", concatenated_conversations)\n",
    "\n",
    "        # Assume an async version of LLM analysis\n",
    "        if concatenated_conversations:\n",
    "            conclusion_summary = await self.analyze_conversations(concatenated_conversations)\n",
    "            if \"uninspiring\" not in conclusion_summary.lower():\n",
    "                timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "                conclusion_filename = f\"conclusions/conclusion_{timestamp}.txt\"\n",
    "                with open(conclusion_filename, \"w\") as file:\n",
    "                    file.write(conclusion_summary)\n",
    "                self.overwhelmed.set()\n",
    "            stm.forget_keywords(interesting_keywords)\n",
    "        else:\n",
    "            return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "74630199-9349-45a3-bd97-4b136d64ebba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanInteraction:\n",
    "    \"\"\"\n",
    "    A class that manages the interaction between a human user and a language learning model (LLM).\n",
    "\n",
    "    This class handles initializing conversation parameters, managing user input, generating\n",
    "    responses using an LLM, and saving conversation history.\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, llm, ready_for_input_event, conversing_event):\n",
    "        \"\"\"\n",
    "        Initializes the HumanInteraction class.\n",
    "\n",
    "        Sets up the conversation environment, including the conversation prompt, keywords prompt,\n",
    "        and conversation chain with the LLM.\n",
    "\n",
    "        Args:\n",
    "            llm: The language learning model used for generating conversation responses.\n",
    "            ready_for_input_event: An event flag indicating readiness for user input.\n",
    "            conversing_event: An event flag indicating an ongoing conversation.\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"SYSTEM MESSAGE: Initializing HumanInteraction\")\n",
    "\n",
    "        self.ready_for_input = ready_for_input_event\n",
    "        self.conversing = conversing_event\n",
    "\n",
    "        self.llm = llm\n",
    "        self.chat_memory = ConversationBufferMemory()\n",
    "        \n",
    "        converstion_prompt_template = PromptManager.get_prompt(\"human_interaction\")\n",
    "        conversation_prompt = PromptTemplate.from_template(converstion_prompt_template)\n",
    "        self.conversation_chain = ConversationChain(llm=self.llm,\n",
    "                                                    prompt=conversation_prompt,\n",
    "                                                    memory=self.chat_memory)\n",
    "\n",
    "        self.keywords_generation_prompt_template = PromptManager.get_prompt(\"keyword_generation\")\n",
    "                \n",
    "        self.user_input = None\n",
    "        \n",
    "        self.inactivity_count = 0\n",
    "        self.inactivity_limit = 60  # 60 seconds of inactivity\n",
    "    \n",
    "    async def start_conversation(self):\n",
    "        \"\"\"\n",
    "        Starts the conversation loop.\n",
    "\n",
    "        This asynchronous method continually checks for user input, processes it,\n",
    "        and generates responses using the LLM. The loop ends when the user inputs \"end chat\"\n",
    "        or when the inactivity limit is reached.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"Let's engage in a conversation...\")\n",
    "        while True:\n",
    "            if self.user_input:\n",
    "                self.ready_for_input.clear()  # Signal that the handler is busy\n",
    "                print(f\"Received user input: {self.user_input}\")\n",
    "\n",
    "                if self.user_input.lower() == \"end chat\":\n",
    "                    await self.end_conversation()\n",
    "                    break\n",
    "\n",
    "                # rint(\"SYSTEM MESSAGE: Generating response\") \n",
    "                response = await self.conversation_chain.apredict(input=self.user_input)\n",
    "                print(\"AI:\", response)\n",
    "                self.user_input = None\n",
    "                self.ready_for_input.set()  # Signal that the handler is ready for new input\n",
    "                self.inactivity_count = 0\n",
    "            else:\n",
    "                await asyncio.sleep(1)\n",
    "                self.inactivity_count += 1\n",
    "                if self.inactivity_count >= self.inactivity_limit:\n",
    "                    await self.end_conversation()\n",
    "                    break\n",
    "\n",
    "    async def end_conversation(self):\n",
    "        \"\"\"\n",
    "        Ends the conversation.\n",
    "\n",
    "        This method saves the conversation history, clears event flags, and performs\n",
    "        necessary cleanup actions.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(\"SYSTEM MESSAGE: Ending conversation\")\n",
    "        self._save_conversation_history()\n",
    "        self.conversing.clear()\n",
    "        self.ready_for_input.set() \n",
    "        self.inactivity_count = 0\n",
    "        # Any other cleanup or final actions can be added here    \n",
    "\n",
    "    def _save_conversation_history(self):\n",
    "        \"\"\"\n",
    "        Saves the conversation history to a file.\n",
    "\n",
    "        The conversation history is saved with a timestamp and a summary of the conversation\n",
    "        is generated and printed.\n",
    "        \"\"\"\n",
    "        \n",
    "        # print(\"SYSTEM MESSAGE: Saving conversation history\")\n",
    "        conversation_keywords = self._summarize_conversation()\n",
    "        conversation_history = self.chat_memory.load_memory_variables(inputs={})['history']\n",
    "        print(conversation_keywords)\n",
    "        timestamp = datetime.datetime.now().strftime(\"%Y%m%d%H%M%S\")\n",
    "        conversation_filename = f\"conversations/conversation_{timestamp}.txt\"\n",
    "        with open(conversation_filename, \"w\") as file:\n",
    "            file.write(conversation_history)\n",
    "\n",
    "        # Update the ShortTermMemory with the conversation and its keywords\n",
    "        stm = ShortTermMemory()  # Assuming ShortTermMemory is already defined elsewhere\n",
    "        stm.memorize(conversation_keywords, conversation_filename)\n",
    "    \n",
    "    def _summarize_conversation(self):\n",
    "        \"\"\"\n",
    "        Summarizes the conversation and returns the list of relevant keywords.\n",
    "\n",
    "        Args:\n",
    "            chat_history (str): The conversation history to summarize.\n",
    "\n",
    "        Returns:\n",
    "            list: A list of keywords summarizing the conversation.\n",
    "        \"\"\"\n",
    "        #print(\"SYSTEM MESSAGE: Summarizing conversation\")\n",
    "        chat_history = self.chat_memory.load_memory_variables(inputs={})['history']\n",
    "        keywords_generation_prompt = self.keywords_generation_prompt_template.replace(\"{chat_history}\", chat_history)\n",
    "        #print(\"Keywords prompt:\\n\", keywords_generation_prompt)\n",
    "        #print(\"SYSTEM MESSAGE: LLM generating the keywords\")\n",
    "        keywords_generated_raw_output = self.llm(keywords_generation_prompt)\n",
    "        #print(\"SYSTEM MESSAGE: Keywords generated:\", keywords_generated_raw_output)\n",
    "        keywords_generated_pure = PromptManager.extract_keywords(keywords_generated_raw_output)\n",
    "        #print(\"SYSTEM MESSAGE: Keywords extracted:\", keywords_generated_pure)\n",
    "        return keywords_generated_pure\n",
    "\n",
    "    def set_user_input(self, input):\n",
    "        \"\"\"\n",
    "        Acquire the user input for processing.\n",
    "\n",
    "        Args:\n",
    "            input (str): The user input to be processed.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(f\"Acquiring user input in HumanInteraction: {input}\")\n",
    "        self.user_input = input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a13bc35b-555d-4573-95ba-e8542d1b6a94",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CognitiveFeedbackRouter:\n",
    "    def __init__(self, model_path: str = \"llama-2-13b-chat.Q6_K.gguf\", agents_dict: dict = {}):\n",
    "        \"\"\"\n",
    "        A class that manages the routing of cognitive feedback based on user input and system states.\n",
    "    \n",
    "        This class orchestrates various components, including a language learning model (LLM), user input handling,\n",
    "        and managing different operational modes based on system states like 'sleeping' or 'overwhelmed'.\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"SYSTEM MESSAGE: Initializing CognitiveFeedbackRouter\")\n",
    "        self.agents = agents_dict\n",
    "        self.user_input = None\n",
    "        self.overwhelmed = asyncio.Event()\n",
    "        self.sleeping = asyncio.Event()\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.llm = None\n",
    "        self.model_path = model_path\n",
    "        self.conversation_handler = None\n",
    "        self.ready_for_input = asyncio.Event()\n",
    "        self.ready_for_input.set()  # Initially set to ready\n",
    "        self.conversing = asyncio.Event()\n",
    "\n",
    "    async def wakeup(self):\n",
    "        \"\"\"\n",
    "        Wakes up the system and initializes the LLM.\n",
    "\n",
    "        This asynchronous method acquires a lock to ensure thread-safe operations while initializing the LLM.\n",
    "        It clears the 'sleeping' and 'overwhelmed' states and prints confirmation of the wake-up process.\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"SYSTEM MESSAGE: Attempting to wake up...\")\n",
    "        async with self.lock:\n",
    "            print(\"I'm waking up...\")\n",
    "            self.llm = LlamaCpp(model_path=self.model_path, \n",
    "                                n_ctx=4096, \n",
    "                                max_tokens=4000,\n",
    "                                n_batch=16)\n",
    "            self.sleeping.clear()\n",
    "            self.overwhelmed.clear()\n",
    "            print(\"Now I'm fully awaken.\")\n",
    "\n",
    "    async def get_user_input(self):\n",
    "        \"\"\"\n",
    "        Continuously captures user input in an asynchronous loop.\n",
    "\n",
    "        This method waits for the system to be ready for input, then captures and stores user input.\n",
    "        It clears the 'ready for input' state after capturing the input.\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"SYSTEM MESSAGE: Starting user input loop\")\n",
    "        while True:\n",
    "            await self.ready_for_input.wait()\n",
    "            user_input = await asyncio.get_event_loop().run_in_executor(None, input, \"Enter something: \")\n",
    "            print(f\"User input received: {user_input}\")\n",
    "            self.user_input = user_input\n",
    "            self.ready_for_input.clear()\n",
    "\n",
    "    async def mode_selection(self):\n",
    "        \"\"\"\n",
    "        Manages the mode of operation based on user input and system states.\n",
    "\n",
    "        This asynchronous method processes user inputs, manages conversation sessions,\n",
    "        and handles the 'sleeping' and 'overwhelmed' states of the system.\n",
    "        \"\"\"\n",
    "        \n",
    "        #print(\"SYSTEM MESSAGE: Starting mode selection loop\")\n",
    "        while True:\n",
    "            if not self.sleeping.is_set():\n",
    "                if self.user_input:\n",
    "                    print(f\"Processing user input: {self.user_input}\")\n",
    "                    if not self.conversing.is_set():\n",
    "                        #print(\"SYSTEM MESSAGE: Starting new conversation session\")\n",
    "                        self.conversing.set()\n",
    "                        self.conversation_handler = HumanInteraction(self.llm, self.ready_for_input, self.conversing)\n",
    "                        asyncio.create_task(self.conversation_handler.start_conversation())\n",
    "                    self.conversation_handler.set_user_input(self.user_input)\n",
    "                    self.user_input = None\n",
    "                elif self.overwhelmed.is_set():\n",
    "                    #print(\"SYSTEM MESSAGE: Overwhelmed state detected. Going to sleep.\")\n",
    "                    self.sleeping.set()\n",
    "                    await self.agents['REM']['class'].sleep()\n",
    "                    asyncio.create_task(self.wakeup())\n",
    "                else:\n",
    "                    print(\"Pondering the nature of things...\")\n",
    "                    dmn = DefaultModeNetwork(slef.llm, self.overwhelmed)\n",
    "                    await dmn.run()\n",
    "            else:\n",
    "                await asyncio.sleep(1)\n",
    "\n",
    "    async def run(self):\n",
    "        \"\"\"\n",
    "        Initiates and runs the main functionality of the CognitiveFeedbackRouter.\n",
    "\n",
    "        This method starts the system by waking it up, initiating user input capture, and entering the mode selection loop.\n",
    "        \"\"\"\n",
    "        \n",
    "        print(\"SYSTEM MESSAGE: Running CognitiveFeedbackRouter\")\n",
    "        await self.wakeup()\n",
    "        asyncio.create_task(self.get_user_input())\n",
    "        await self.mode_selection()\n",
    "\n",
    "reflective_evolution_monitor = aa.ReflectiveEvolutionMonitor()\n",
    "\n",
    "global_agents = {\n",
    "    'REM': {'Description': 'Desc3', 'class': reflective_evolution_monitor},\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9f50f3-4788-434c-8941-448c2ba643a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "router = CognitiveFeedbackRouter(agents_dict=global_agents)\n",
    "asyncio.run(router.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778a5484-1535-4436-8280-ace67cc33370",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
