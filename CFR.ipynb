{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b8bd7f9f-f3be-4fc5-979c-c76c934f8a7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "\n",
    "# for LLM\n",
    "from langchain.llms import LlamaCpp\n",
    "from langchain.callbacks.manager import CallbackManager\n",
    "from langchain.callbacks.streaming_stdout import StreamingStdOutCallbackHandler\n",
    "from langchain.prompts import PromptTemplate\n",
    "\n",
    "# AGI Agents\n",
    "import AGI_agents as aa\n",
    "\n",
    "# Apply the necessary setup for Jupyter Notebook\n",
    "import nest_asyncio\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0a201af0-884c-4159-8d3e-91a3fe6e0eea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waking up...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Now I'm fully awaken.\n",
      "1\n",
      "2\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Enter something:  What would be a good question?\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is input: What would be a good question?.\n",
      "This is the answer: \n",
      "I'm happy to help! A good question for your critical thinking exercise could depend on the context and goals of the activity. Here are some examples of open-ended questions that could lead to interesting discussions and analysis:\n",
      "1. What do you think is the most pressing social issue facing society today, and why? How would you address it?\n",
      "2. Should there be limits to free speech, and if so, what might those limits be? Why or why not?\n",
      "3. In what ways can technology improve our lives, and in what ways can it harm us? What are some potential solutions to mitigate the negative effects of technology?\n",
      "4. How do you think humanity will change in the next 50 years? What advancements do you predict, and what challenges might we face?\n",
      "5. What are some potential solutions to address climate change, and how can individuals contribute to reducing their carbon footprint?\n",
      "6. Should there be a universal basic income for all citizens, and why or why not? How would such a policy impact society?\n",
      "7. In what ways can we promote empathy and understanding among different cultures and communities? What are some potential strategies for fostering greater social cohesion?\n",
      "8. What do you think is the most important quality for a leader to have, and why? How can individuals develop this quality in themselves?\n",
      "9. In what ways can we improve access to education for marginalized groups, such as those living in poverty or those with disabilities? What are some potential solutions to address these challenges?\n",
      "10. What are some potential strategies for reducing economic inequality, and how can individuals contribute to this effort?\n",
      "Remember, the goal of critical thinking is to encourage learners to think deeply and thoughtfully about a topic, consider multiple perspectives, and develop well-reasoned arguments. Choose a question that will inspire these types of discussions and analysis!.\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 96\u001b[0m\n\u001b[0;32m     94\u001b[0m \u001b[38;5;66;03m# Create an instance of the class and run it\u001b[39;00m\n\u001b[0;32m     95\u001b[0m router \u001b[38;5;241m=\u001b[39m CognitiveFeedbackRouter(agents_dict\u001b[38;5;241m=\u001b[39mglobal_agents)\n\u001b[1;32m---> 96\u001b[0m \u001b[43masyncio\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrouter\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\nest_asyncio.py:31\u001b[0m, in \u001b[0;36m_patch_asyncio.<locals>.run\u001b[1;34m(main, debug)\u001b[0m\n\u001b[0;32m     29\u001b[0m task \u001b[38;5;241m=\u001b[39m asyncio\u001b[38;5;241m.\u001b[39mensure_future(main)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mloop\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_until_complete\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     32\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m task\u001b[38;5;241m.\u001b[39mdone():\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\nest_asyncio.py:93\u001b[0m, in \u001b[0;36m_patch_loop.<locals>.run_until_complete\u001b[1;34m(self, future)\u001b[0m\n\u001b[0;32m     91\u001b[0m     f\u001b[38;5;241m.\u001b[39m_log_destroy_pending \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m     92\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m f\u001b[38;5;241m.\u001b[39mdone():\n\u001b[1;32m---> 93\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run_once\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     94\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping:\n\u001b[0;32m     95\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\nest_asyncio.py:116\u001b[0m, in \u001b[0;36m_patch_loop.<locals>._run_once\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    109\u001b[0m     heappop(scheduled)\n\u001b[0;32m    111\u001b[0m timeout \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    112\u001b[0m     \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m ready \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_stopping\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mmin\u001b[39m(\u001b[38;5;28mmax\u001b[39m(\n\u001b[0;32m    114\u001b[0m         scheduled[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39m_when \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime(), \u001b[38;5;241m0\u001b[39m), \u001b[38;5;241m86400\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m scheduled\n\u001b[0;32m    115\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m--> 116\u001b[0m event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    117\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_process_events(event_list)\n\u001b[0;32m    119\u001b[0m end_time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtime() \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_clock_resolution\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\selectors.py:323\u001b[0m, in \u001b[0;36mSelectSelector.select\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    321\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m    322\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 323\u001b[0m     r, w, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_select\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_readers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_writers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    324\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[0;32m    325\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "File \u001b[1;32m~\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\selectors.py:314\u001b[0m, in \u001b[0;36mSelectSelector._select\u001b[1;34m(self, r, w, _, timeout)\u001b[0m\n\u001b[0;32m    313\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_select\u001b[39m(\u001b[38;5;28mself\u001b[39m, r, w, _, timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[1;32m--> 314\u001b[0m     r, w, x \u001b[38;5;241m=\u001b[39m \u001b[43mselect\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    315\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m r, w \u001b[38;5;241m+\u001b[39m x, []\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "class CognitiveFeedbackRouter:\n",
    "    def __init__(self, model_path: str = \"llama-2-7b-chat.Q4_K_M.gguf\", agents_dict: dict = {}):\n",
    "        self.agents = agents_dict\n",
    "        self.number = 0\n",
    "        self.stored_input = ''\n",
    "        self.urgent_task = asyncio.Event()\n",
    "        self.sleeping = asyncio.Event()\n",
    "        self.lock = asyncio.Lock()\n",
    "        self.llm = None\n",
    "        self.model_path = model_path\n",
    "\n",
    "    async def wakeup(self):\n",
    "        async with self.lock:  # Acquire the lock\n",
    "            # Logic for wakeup\n",
    "            print(\"Waking up...\")\n",
    "            self.llm = LlamaCpp(\n",
    "                model_path=\"llama-2-7b-chat.Q4_K_M.gguf\",\n",
    "                max_tokens=100000)\n",
    "            \n",
    "            if self.urgent_task.is_set():\n",
    "                print(f\"I urgently need to take care of something.\")\n",
    "            self.sleeping.clear()\n",
    "            print(\"Now I'm fully awaken.\")\n",
    "\n",
    "    async def deepsleep(self):\n",
    "        async with self.lock:  # Acquire the lock\n",
    "            # Logic for deepsleep\n",
    "            print(\"Zzzzzz...\")\n",
    "            self.sleeping.set()\n",
    "            await asyncio.sleep(5)  # Simulate some work\n",
    "            asyncio.create_task(self.wakeup())\n",
    "\n",
    "    async def get_user_input(self):\n",
    "        while True:\n",
    "            user_input = await asyncio.get_event_loop().run_in_executor(None, input, \"Enter something: \")\n",
    "            if self.sleeping.is_set():\n",
    "                self.stored_input = user_input\n",
    "            else:\n",
    "                await self.agents['Human interaction']['class'].run(self.llm, user_input)\n",
    "\n",
    "    async def decide_what_to_do(self):\n",
    "        while True:\n",
    "            if not self.sleeping.is_set():\n",
    "                self.number += 1\n",
    "                if self.stored_input:\n",
    "                    await self.agents['Human interaction']['class'].run(self.llm, self.stored_input)\n",
    "                    self.stored_input = None  # Clear stored input after processing\n",
    "                    #elif self.number%5 == 0:\n",
    "                    #    print(self.number)\n",
    "                    #    await self.deepsleep()\n",
    "                else:\n",
    "                    print(self.number)\n",
    "                    await self.agents['Contemplation']['class'].run()\n",
    "            else:\n",
    "                await asyncio.sleep(1)\n",
    "            \n",
    "            await self.decide_what_to_do()\n",
    "    \n",
    "    async def run(self):\n",
    "        await self.wakeup()\n",
    "        \n",
    "        input_task = asyncio.create_task(self.get_user_input())\n",
    "        \n",
    "        await self.decide_what_to_do()\n",
    "\n",
    "\n",
    "class HumanInteraction:\n",
    "    def __init__(self):\n",
    "        self.description = \"Human interaction agent placeholder\"\n",
    "\n",
    "    async def run(self, llm, input):\n",
    "        print(f\"This is input: {input}.\")\n",
    "        prompt_template = PromptTemplate.from_template(\"Could you please answer this: {input}?\")\n",
    "        chain = prompt_template | llm\n",
    "        result = chain.invoke({'input': input})\n",
    "        print(f\"This is the answer: {result}.\")\n",
    "\n",
    "class Contemplation:\n",
    "    def __init__(self):\n",
    "        self.description = \"Self-contemplation placeholer\"\n",
    "\n",
    "    async def run(self):\n",
    "        #print(\"Contemplating...\")\n",
    "        await asyncio.sleep(10)  # Simulate contemplation\n",
    "\n",
    "agent_hint = HumanInteraction()\n",
    "agent_cont = Contemplation()\n",
    "\n",
    "global_agents = {\n",
    "    'Human interaction': {'Description': 'Desc1', 'class': agent_hint}, \n",
    "    'Contemplation': {'Description': 'Desc2', 'class': agent_cont}\n",
    "}\n",
    "\n",
    "# Create an instance of the class and run it\n",
    "router = CognitiveFeedbackRouter(agents_dict=global_agents)\n",
    "asyncio.run(router.run())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b2ea2e5c-0fe1-4c64-99ee-2d677e63a90f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "AVX = 1 | AVX2 = 1 | AVX512 = 0 | AVX512_VBMI = 0 | AVX512_VNNI = 0 | FMA = 1 | NEON = 0 | ARM_FMA = 0 | F16C = 1 | FP16_VA = 0 | WASM_SIMD = 0 | BLAS = 0 | SSE3 = 1 | SSSE3 = 0 | VSX = 0 | \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This is input: 2+2.\n",
      "This is the answer .\n"
     ]
    }
   ],
   "source": [
    "llm = LlamaCpp(model_path=\"llama-2-7b-chat.Q4_K_M.gguf\", max_tokens=100000)\n",
    "\n",
    "class HumanInteraction:\n",
    "    def __init__(self):\n",
    "        self.description = \"Human interaction agent placeholder\"\n",
    "\n",
    "    async def run(self, llm, input):\n",
    "        print(f\"This is input: {input}.\")\n",
    "        prompt_template = PromptTemplate.from_template(\"Could you please answer this: {input}?\")\n",
    "        chain = prompt_template | llm\n",
    "        result = chain.invoke({'input': input})\n",
    "        print(f\"This is the answer {result}.\")\n",
    "\n",
    "class Contemplation:\n",
    "    def __init__(self):\n",
    "        self.description = \"Self-contemplation placeholer\"\n",
    "\n",
    "    async def run(self):\n",
    "        #print(\"Contemplating...\")\n",
    "        await asyncio.sleep(10)  # Simulate contemplation\n",
    "agent_hint = HumanInteraction()\n",
    "agent_cont = Contemplation()\n",
    "\n",
    "global_agents = {\n",
    "    'Human interaction': {'Description': 'Desc1', 'class': agent_hint}, \n",
    "    'Contemplation': {'Description': 'Desc2', 'class': agent_cont}\n",
    "}\n",
    "\n",
    "result = await global_agents['Human interaction']['class'].run(input='2+2', llm=llm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1c124fd9-7fd1-4536-9fdf-d5e3843c7c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_template = PromptTemplate.from_template(\"Could you please answer this: {input}?\")\n",
    "chain = prompt_template | llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd489bf6-9a15-46ee-8e9d-e4fb3ea77a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = \"What do you find interesting?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f094eac0-d8ea-4b61-996e-91051ca2c4fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Llama.generate: prefix-match hit\n",
      "C:\\Users\\siwiakma\\AppData\\Roaming\\jupyterlab-desktop\\jlab_server\\lib\\site-packages\\langchain\\llms\\llamacpp.py:352: RuntimeWarning: coroutine 'AsyncCallbackManagerForLLMRun.on_llm_new_token' was never awaited\n",
      "  run_manager.on_llm_new_token(\n",
      "RuntimeWarning: Enable tracemalloc to get the object allocation traceback\n",
      "Llama.generate: prefix-match hit\n"
     ]
    }
   ],
   "source": [
    "result = chain.ainvoke({'input': input})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4faa5a80-9f27-445f-90e7-527b89ba2a69",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PromptTemplate(input_variables=['input'], template='Could you please answer this: {input}?')\n",
       "| LlamaCpp(client=<llama_cpp.llama.Llama object at 0x00000288F7CEF6D0>, model_path='llama-2-7b-chat.Q4_K_M.gguf')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ab719c9f-3d47-4483-97cc-6b7d26a1d879",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LLMResult(generations=[[Generation(text=\"\\n\\nI'm just an AI, I don't have personal preferences or interests like humans do. However, I can provide information on a wide range of topics including science, technology, history, culture, and more. Is there something specific you would like to know or discuss?\")]], llm_output=None, run=[RunInfo(run_id=UUID('808c103a-019b-4130-8d65-edff1cc8bb54'))])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c977f5d3-ef81-4f0e-b9f0-985e22258b62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nI'm getting this error message while trying to execute a cell in Jupyter notebook. The cell contains the following line:\\n`raw_input(y)`\\nI'm using Python 3.7.4 and Jupyter Notebook 2.1.0. I believe that the issue might be related to the fact that `raw_input()` is deprecated in Python 3.7, but I couldn't find any solution so far. Any help would be greatly appreciated!\\n\\n\\n\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad77b059-c1a2-4016-bd8a-ce2d2dd9bf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import Tool, AgentExecutor, LLMSingleActionAgent, AgentOutputParser\n",
    "from langchain.prompts import StringPromptTemplate\n",
    "from langchain.llms import OpenAI\n",
    "from langchain.chains import LLMChain\n",
    "import re\n",
    "from AGI_templates import interaction_template\n",
    "\n",
    "# Define the custom prompt template\n",
    "class CustomPromptTemplate(StringPromptTemplate):\n",
    "    template = interaction_template  # Your provided template\n",
    "\n",
    "    def format(self, **kwargs) -> str:\n",
    "        # Include logic for formatting the prompt with tools, input, etc.\n",
    "        # ...\n",
    "\n",
    "# Define tools\n",
    "search = SerpAPIWrapper()  # Assuming a search tool\n",
    "tools = [Tool(name=\"Search\", func=search.run, description=\"...\")]\n",
    "\n",
    "# Define the output parser\n",
    "class CustomOutputParser(AgentOutputParser):\n",
    "    def parse(self, llm_output: str):\n",
    "        # Logic to parse the output and decide if all angles are covered\n",
    "        # ...\n",
    "\n",
    "# Set up LLM and the agent\n",
    "prompt = CustomPromptTemplate(tools=tools, ...)\n",
    "llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "agent = LLMSingleActionAgent(llm_chain=llm_chain, output_parser=CustomOutputParser(), ...)\n",
    "\n",
    "# Run the agent\n",
    "agent_executor = AgentExecutor.from_agent_and_tools(agent=agent, tools=tools, verbose=True)\n",
    "result = agent_executor.run(\"Your input here\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf54dab3-275c-4746-b632-f2f9a29152ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class HumanInteractionAgent:\n",
    "    def __init__(self, llm, prompt_template, output_parser, tools):\n",
    "        self.llm = llm\n",
    "        self.prompt_template = prompt_template\n",
    "        self.output_parser = output_parser\n",
    "        self.tools = tools\n",
    "        self.context = []  # For storing intermediate steps\n",
    "\n",
    "    def receive_input(self, user_input):\n",
    "        # Process the initial user input\n",
    "        ...\n",
    "\n",
    "    def generate_prompt(self):\n",
    "        # Use the prompt template to format the input and context\n",
    "        ...\n",
    "\n",
    "    def consult_llm(self, formatted_prompt):\n",
    "        # Send the formatted prompt to the LLM and get a response\n",
    "        ...\n",
    "\n",
    "    def parse_output(self, llm_output):\n",
    "        # Interpret the LLM's response using the output parser\n",
    "        ...\n",
    "\n",
    "    def decide_action(self, parsed_output):\n",
    "        # Decide what action to take based on the parsed output\n",
    "        ...\n",
    "\n",
    "    def perform_action(self, action, action_input):\n",
    "        # Perform the suggested action using one of the tools\n",
    "        ...\n",
    "\n",
    "    def iterate_interaction(self):\n",
    "        # Repeat the process (prompt generation, LLM consultation, etc.)\n",
    "        ...\n",
    "\n",
    "    def conclude_interaction(self):\n",
    "        # Finalize and format the response, and conclude the interaction\n",
    "        ...\n",
    "\n",
    "# Usage\n",
    "agent = CustomLangChainAgent(llm, prompt_template, output_parser, tools)\n",
    "response = agent.receive_input(\"User's question\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f8d283a1-50ff-4de8-8da2-7cad1decc82a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['.chainlit', '.ipynb_checkpoints', '.jupyter', 'AGI.pdf', 'AGI_templates.py', 'CFA.ipynb', 'CFR.ipynb', 'chainlit.md', 'CodeLlama', 'codellama-7b.Q4_K_M.gguf', 'cypher.py', 'graph_document.py', 'Graph_Layer.ipynb', 'graph_store.py', 'langchain_neo4j.ipynb', 'Library', 'llama-2-7b-chat.Q4_K_M.gguf', 'llama-2-7b-chat.Q6_K.gguf', 'LLM.ipynb', 'neo4j', 'neo4j_graph.py', 'SRI.ipynb', '__pycache__']\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.listdir(os.getcwd()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1b5aa0a-bd05-412a-9586-c288d48814b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
